<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="preload" href="/_next/static/media/graziano-casto.17cc67b9.jpg" as="image" fetchpriority="high"/><title>Graziano Casto - DevRel Engineer</title><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"Graziano Casto WebSite","alternateName":"Graziano's WebSite","url":"https://castograziano.com"}</script><meta name="description" content="Welcome to the personal website of Graziano Casto."/><link rel="canonical" href="https://www.castograziano.comhttps://castograziano.com"/><meta property="og:title" content="Graziano Casto - DevRel Engineer"/><meta property="og:description" content="Welcome to the personal website of Graziano Casto."/><meta property="og:url" content="https://www.castograziano.comhttps://castograziano.com"/><meta property="og:image" content="https://castograziano.com/casto-graziano.jpg"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Graziano Casto - DevRel Engineer"/><meta name="twitter:description" content="Welcome to the personal website of Graziano Casto."/><meta name="twitter:image" content="https://castograziano.com/casto-graziano.jpg"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="icon" href="/images/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"/><meta name="next-head-count" content="20"/><link rel="preload" href="/_next/static/css/999d5f2b05d61cff.css" as="style"/><link rel="stylesheet" href="/_next/static/css/999d5f2b05d61cff.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-0b5d8249fb15f5f3.js" defer=""></script><script src="/_next/static/chunks/framework-2c16ac744b6cdea6.js" defer=""></script><script src="/_next/static/chunks/main-69b16c27ce463005.js" defer=""></script><script src="/_next/static/chunks/pages/_app-666f3c6bf21653ac.js" defer=""></script><script src="/_next/static/chunks/762-da5643961ae757ec.js" defer=""></script><script src="/_next/static/chunks/pages/index-c7e84f72e2c25659.js" defer=""></script><script src="/_next/static/cX5uW1vCazRxt3VxGRD10/_buildManifest.js" defer=""></script><script src="/_next/static/cX5uW1vCazRxt3VxGRD10/_ssgManifest.js" defer=""></script></head><body><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="flex w-full"><div class="fixed inset-0 flex justify-center sm:px-8"><div class="flex w-full max-w-7xl lg:px-8"><div class="w-full bg-white ring-1 ring-zinc-100 dark:bg-zinc-900 dark:ring-zinc-300/20"></div></div></div><div class="relative flex w-full flex-col"><header class="pointer-events-none relative z-50 flex flex-none flex-col" style="height:var(--header-height);margin-bottom:var(--header-mb)"><div class="order-last mt-[calc(theme(spacing.16)-theme(spacing.3))]"></div><div class="sm:px-8 top-0 order-last -mb-3 pt-3" style="position:var(--header-position)"><div class="mx-auto w-full max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="top-[var(--avatar-top,theme(spacing.3))] w-full" style="position:var(--header-inner-position)"><div class="relative"><div class="absolute left-0 top-3 origin-left transition-opacity h-10 w-10 rounded-full bg-white/90 p-0.5 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur dark:bg-zinc-800/90 dark:ring-white/10" style="opacity:var(--avatar-border-opacity, 0);transform:var(--avatar-border-transform)"></div><a aria-label="Home" class="block h-16 w-16 origin-left pointer-events-auto" style="transform:var(--avatar-image-transform)" href="/"><img alt="" fetchpriority="high" width="1872" height="1914" decoding="async" data-nimg="1" class="rounded-full bg-zinc-100 object-cover dark:bg-zinc-800 h-16 w-16" style="color:transparent" src="/_next/static/media/graziano-casto.17cc67b9.jpg"/></a></div></div></div></div></div></div><div class="top-0 z-10 h-16 pt-6" style="position:var(--header-position)"><div class="sm:px-8 top-[var(--header-top,theme(spacing.6))] w-full" style="position:var(--header-inner-position)"><div class="mx-auto w-full max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="relative flex gap-4"><div class="flex flex-1"></div><div class="flex flex-1 justify-end md:justify-center"><div class="pointer-events-auto md:hidden" data-headlessui-state=""><button class="group flex items-center rounded-full bg-white/90 px-4 py-2 text-sm font-medium text-zinc-800 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur dark:bg-zinc-800/90 dark:text-zinc-200 dark:ring-white/10 dark:hover:ring-white/20" type="button" aria-expanded="false" data-headlessui-state="">Menu<svg viewBox="0 0 8 6" aria-hidden="true" class="ml-3 h-auto w-2 stroke-zinc-500 group-hover:stroke-zinc-700 dark:group-hover:stroke-zinc-400"><path d="M1.75 1.75 4 4.25l2.25-2.5" fill="none" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><div hidden="" style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div><nav class="pointer-events-auto hidden md:block"><ul class="flex rounded-full bg-white/90 px-3 text-sm font-medium text-zinc-800 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur dark:bg-zinc-800/90 dark:text-zinc-200 dark:ring-white/10"><li><a class="relative block px-3 py-2 transition hover:text-teal-500 dark:hover:text-teal-400" href="/about-me/">About</a></li><li><a class="relative block px-3 py-2 transition hover:text-teal-500 dark:hover:text-teal-400" href="/articles/">Articles</a></li><li><a class="relative block px-3 py-2 transition hover:text-teal-500 dark:hover:text-teal-400" href="/speaking/">Speaking</a></li><li><a class="relative block px-3 py-2 transition hover:text-teal-500 dark:hover:text-teal-400" href="/projects/">Projects</a></li></ul></nav></div><div class="flex justify-end md:flex-1"><div class="pointer-events-auto"><button type="button" aria-label="Toggle theme" class="group rounded-full bg-white/90 px-3 py-2 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 backdrop-blur transition dark:bg-zinc-800/90 dark:ring-white/10 dark:hover:ring-white/20"><svg viewBox="0 0 24 24" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" class="h-6 w-6 fill-zinc-100 stroke-zinc-500 transition group-hover:fill-zinc-200 group-hover:stroke-zinc-700 dark:hidden [@media(prefers-color-scheme:dark)]:fill-teal-50 [@media(prefers-color-scheme:dark)]:stroke-teal-500 [@media(prefers-color-scheme:dark)]:group-hover:fill-teal-50 [@media(prefers-color-scheme:dark)]:group-hover:stroke-teal-600"><path d="M8 12.25A4.25 4.25 0 0 1 12.25 8v0a4.25 4.25 0 0 1 4.25 4.25v0a4.25 4.25 0 0 1-4.25 4.25v0A4.25 4.25 0 0 1 8 12.25v0Z"></path><path d="M12.25 3v1.5M21.5 12.25H20M18.791 18.791l-1.06-1.06M18.791 5.709l-1.06 1.06M12.25 20v1.5M4.5 12.25H3M6.77 6.77 5.709 5.709M6.77 17.73l-1.061 1.061" fill="none"></path></svg><svg viewBox="0 0 24 24" aria-hidden="true" class="hidden h-6 w-6 fill-zinc-700 stroke-zinc-500 transition dark:block [@media(prefers-color-scheme:dark)]:group-hover:stroke-zinc-400 [@media_not_(prefers-color-scheme:dark)]:fill-teal-400/10 [@media_not_(prefers-color-scheme:dark)]:stroke-teal-500"><path d="M17.25 16.22a6.937 6.937 0 0 1-9.47-9.47 7.451 7.451 0 1 0 9.47 9.47ZM12.75 7C17 7 17 2.75 17 2.75S17 7 21.25 7C17 7 17 11.25 17 11.25S17 7 12.75 7Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div></div></div></div></div></div></div></header><div class="flex-none" style="height:var(--content-offset)"></div><main class="flex-auto"><div class="sm:px-8 mt-9"><div class="mx-auto w-full max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="max-w-2xl"><h1 class="text-4xl font-bold tracking-tight text-zinc-800 sm:text-5xl dark:text-zinc-100">Graziano Casto üëãüèª</h1><p class="mt-6 text-base text-zinc-600 dark:text-zinc-400"> Developer Relations | Kubernetes v1.35 Release Comms Lead | CNCF TAG Developer Experience Tech Lead | Cloud Native Days Italy Organizer | OSS &amp; Cloud Native Advocate </p><div class="mt-6 flex gap-6"><a class="group -m-1 p-1" aria-label="Follow on GitHub" target="_blank" rel="noopener noreferrer" href="https://github.com/graz-dev"><svg viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6 fill-zinc-500 transition group-hover:fill-zinc-600 dark:fill-zinc-400 dark:group-hover:fill-zinc-300"><path fill-rule="evenodd" clip-rule="evenodd" d="M12 2C6.475 2 2 6.588 2 12.253c0 4.537 2.862 8.369 6.838 9.727.5.09.687-.218.687-.487 0-.243-.013-1.05-.013-1.91C7 20.059 6.35 18.957 6.15 18.38c-.113-.295-.6-1.205-1.025-1.448-.35-.192-.85-.667-.013-.68.788-.012 1.35.744 1.538 1.051.9 1.551 2.338 1.116 2.912.846.088-.666.35-1.115.638-1.371-2.225-.256-4.55-1.14-4.55-5.062 0-1.115.387-2.038 1.025-2.756-.1-.256-.45-1.307.1-2.717 0 0 .837-.269 2.75 1.051.8-.23 1.65-.346 2.5-.346.85 0 1.7.115 2.5.346 1.912-1.333 2.75-1.05 2.75-1.05.55 1.409.2 2.46.1 2.716.637.718 1.025 1.628 1.025 2.756 0 3.934-2.337 4.806-4.562 5.062.362.32.675.936.675 1.897 0 1.371-.013 2.473-.013 2.82 0 .268.188.589.688.486a10.039 10.039 0 0 0 4.932-3.74A10.447 10.447 0 0 0 22 12.253C22 6.588 17.525 2 12 2Z"></path></svg></a><a class="group -m-1 p-1" aria-label="Follow on LinkedIn" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/castograziano/"><svg viewBox="0 0 24 24" aria-hidden="true" class="h-6 w-6 fill-zinc-500 transition group-hover:fill-zinc-600 dark:fill-zinc-400 dark:group-hover:fill-zinc-300"><path d="M18.335 18.339H15.67v-4.177c0-.996-.02-2.278-1.39-2.278-1.389 0-1.601 1.084-1.601 2.205v4.25h-2.666V9.75h2.56v1.17h.035c.358-.674 1.228-1.387 2.528-1.387 2.7 0 3.2 1.778 3.2 4.091v4.715zM7.003 8.575a1.546 1.546 0 01-1.548-1.549 1.548 1.548 0 111.547 1.549zm1.336 9.764H5.666V9.75H8.34v8.589zM19.67 3H4.329C3.593 3 3 3.58 3 4.297v15.406C3 20.42 3.594 21 4.328 21h15.338C20.4 21 21 20.42 21 19.703V4.297C21 3.58 20.4 3 19.666 3h.003z"></path></svg></a></div></div></div></div></div></div><div class="sm:px-8 mt-12"><div class="mx-auto w-full max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="mx-auto grid max-w-4xl grid-cols-1 gap-y-20 lg:max-w-none lg:grid-cols-2 lg:gap-x-12"><a href="https://www.linkedin.com/build-relation/newsletter-follow?entityUrn=7267281680451731457" target="_blank" rel="noopener noreferrer" class="block"><div class="rounded-2xl border border-zinc-100 p-6 dark:border-zinc-700/40"><h2 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100">Cloud Native Friday Newsletter</h2><p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">Subscribe to my LinkedIn newsletter for weekly insights on Cloud Native technologies, Platform Engineering and Developer Experience.</p><div aria-hidden="true" class="relative z-10 mt-2 flex items-center text-sm font-medium text-teal-500">Subscribe on LinkedIn<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></a><a href="https://community.cncf.io/cloud-native-los-angeles/" target="_blank" rel="noopener noreferrer" class="block"><div class="rounded-2xl border border-zinc-100 p-6 dark:border-zinc-700/40"><h2 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100">Pods &amp; Platforms</h2><p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">Discover our event series at CNCF Los Angeles, where industry experts explore the latest trends and best practices in Cloud Native and Platform Engineering.</p><div aria-hidden="true" class="relative z-10 mt-2 flex items-center text-sm font-medium text-teal-500">Watch Now<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></a></div></div></div></div></div><div class="sm:px-8 mt-12"><div class="mx-auto w-full max-w-7xl lg:px-8"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="mx-auto grid max-w-4xl grid-cols-1 gap-y-20 lg:max-w-none lg:grid-cols-2 lg:gap-x-12"><div class="rounded-2xl border border-zinc-100 p-6 dark:border-zinc-700/40"><h2 class="text-sm font-semibold text-zinc-900 dark:text-zinc-100">Latest Articles</h2><div class="mt-6 space-y-8"><a class="block" href="/articles/kubernetes-v134-announcement/"><article class="group relative flex flex-col items-start"><div class="group relative flex flex-col items-start"><h2 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100">Kubernetes v1.34: Of Wind &amp; Will (O&#x27; WaW)</h2><time class="relative z-10 order-first mb-3 flex items-center text-sm text-zinc-400 dark:text-zinc-500 pl-3.5" dateTime="2025-08-27"><span class="absolute inset-y-0 left-0 flex items-center" aria-hidden="true"><span class="h-4 w-0.5 rounded-full bg-zinc-200 dark:bg-zinc-500"></span></span>August 27, 2025</time><p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">Kubernetes v1.34 introduces 58 enhancements including 23 stable features, from Dynamic Resource Allocation (DRA) GA to KYAML support. Discover the latest improvements in security, scheduling, and resource management in this comprehensive release.</p><div aria-hidden="true" class="relative z-10 mt-2 flex items-center text-sm font-medium text-teal-500">Read article<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></article></a><a class="block" href="/articles/ephemetal-cloud-with-crossplane-and-kubegreen/"><article class="group relative flex flex-col items-start"><div class="group relative flex flex-col items-start"><h2 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100">The Ephemeral Cloud: A New Blueprint for Infrastructure Efficiency With Crossplane and kube-green</h2><time class="relative z-10 order-first mb-3 flex items-center text-sm text-zinc-400 dark:text-zinc-500 pl-3.5" dateTime="2025-08-25"><span class="absolute inset-y-0 left-0 flex items-center" aria-hidden="true"><span class="h-4 w-0.5 rounded-full bg-zinc-200 dark:bg-zinc-500"></span></span>August 25, 2025</time><p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">Use Crossplane and kube-green to replace wasteful, always-on cloud environments with on-demand, ephemeral ones, dramatically cutting costs and environmental impact.</p><div aria-hidden="true" class="relative z-10 mt-2 flex items-center text-sm font-medium text-teal-500">Read article<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></article></a><a class="block" href="/articles/kcd-nyc-pe-observability-roundtable/"><article class="group relative flex flex-col items-start"><div class="group relative flex flex-col items-start"><h2 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100">From Chaos to Clarity: Navigating Observability in the Platform Engineering Era (and a Dash of AI)</h2><time class="relative z-10 order-first mb-3 flex items-center text-sm text-zinc-400 dark:text-zinc-500 pl-3.5" dateTime="2025-08-20"><span class="absolute inset-y-0 left-0 flex items-center" aria-hidden="true"><span class="h-4 w-0.5 rounded-full bg-zinc-200 dark:bg-zinc-500"></span></span>August 20, 2025</time><p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">A comprehensive recap of the KCD New York roundtable discussion on Platform Engineering and Observability, exploring key challenges, solutions, and the role of AI in modern observability practices.</p><div aria-hidden="true" class="relative z-10 mt-2 flex items-center text-sm font-medium text-teal-500">Read article<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></article></a><a class="block" href="/articles/wasm-next-universal-runtime/"><article class="group relative flex flex-col items-start"><div class="group relative flex flex-col items-start"><h2 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100">WebAssembly: From Browser Plugin to the Next Universal Runtime</h2><time class="relative z-10 order-first mb-3 flex items-center text-sm text-zinc-400 dark:text-zinc-500 pl-3.5" dateTime="2025-08-04"><span class="absolute inset-y-0 left-0 flex items-center" aria-hidden="true"><span class="h-4 w-0.5 rounded-full bg-zinc-200 dark:bg-zinc-500"></span></span>August 4, 2025</time><p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">Explore WebAssembly&#x27;s evolution from a browser performance booster to a universal runtime reshaping cloud, edge, and distributed computing with near-native performance across platforms.</p><div aria-hidden="true" class="relative z-10 mt-2 flex items-center text-sm font-medium text-teal-500">Read article<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div></article></a></div></div><div class="space-y-10"><div class="rounded-2xl border border-zinc-100 p-6 dark:border-zinc-700/40"><h2 class="text-sm font-semibold text-zinc-900 dark:text-zinc-100">Upcoming Talks</h2><ol class="mt-6 space-y-4"><li class="flex gap-4"><div class="relative mt-1 flex h-10 w-10 flex-none items-center justify-center rounded-full shadow-md shadow-zinc-800/5 ring-1 ring-zinc-900/5 dark:border dark:border-zinc-700/50 dark:bg-zinc-800 dark:ring-0"><svg class="h-6 w-6 text-zinc-400 dark:text-zinc-500" viewBox="0 0 24 24" fill="none" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z" class="fill-zinc-100 stroke-zinc-400 dark:fill-zinc-100/10 dark:stroke-zinc-500"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2" class="stroke-zinc-400 dark:stroke-zinc-500"></path><path d="M12 18v4M8 22h8" class="stroke-zinc-400 dark:stroke-zinc-500"></path></svg></div><dl class="flex flex-auto flex-wrap gap-x-2"><dt class="sr-only">Event</dt><dd class="w-full flex-none text-sm font-medium text-zinc-900 dark:text-zinc-100"><a target="_blank" rel="noopener noreferrer" href="https://community.cncf.io/events/details/cncf-kcd-porto-presents-kcd-porto-2025/">KCD Porto</a></dd><dt class="sr-only">Talk Title</dt><dd class="text-xs text-zinc-500 dark:text-zinc-400">Serving LLMs on Kubernetes: A Golden Path for Platform Engineers</dd><dt class="sr-only">Location and Date</dt><dd class="text-xs text-zinc-500 dark:text-zinc-400">üáµüáπ Porto<!-- --> - <time dateTime="2025-11-03">November 3, 2025</time></dd></dl></li><li class="flex gap-4"><div class="relative mt-1 flex h-10 w-10 flex-none items-center justify-center rounded-full shadow-md shadow-zinc-800/5 ring-1 ring-zinc-900/5 dark:border dark:border-zinc-700/50 dark:bg-zinc-800 dark:ring-0"><svg class="h-6 w-6 text-zinc-400 dark:text-zinc-500" viewBox="0 0 24 24" fill="none" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z" class="fill-zinc-100 stroke-zinc-400 dark:fill-zinc-100/10 dark:stroke-zinc-500"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2" class="stroke-zinc-400 dark:stroke-zinc-500"></path><path d="M12 18v4M8 22h8" class="stroke-zinc-400 dark:stroke-zinc-500"></path></svg></div><dl class="flex flex-auto flex-wrap gap-x-2"><dt class="sr-only">Event</dt><dd class="w-full flex-none text-sm font-medium text-zinc-900 dark:text-zinc-100"><a target="_blank" rel="noopener noreferrer" href="https://www.containerday.it/talk/the-kubernetes-compass-come-navigare-spazio-e-tempo-per-essere-piu-sostenibili/?_gl=1*9vcxdj*_up*MQ..*_ga*MTU3OTMxMzgxNS4xNzUzMTE5Mzk4*_ga_GH3N0VLD75*czE3NTMxMTkzOTUkbzEkZzAkdDE3NTMxMTkzOTUkajYwJGwwJGgw">Container Day</a></dd><dt class="sr-only">Talk Title</dt><dd class="text-xs text-zinc-500 dark:text-zinc-400">The Kubernetes Compass: Navigating Space and Time for Energy Efficiency</dd><dt class="sr-only">Location and Date</dt><dd class="text-xs text-zinc-500 dark:text-zinc-400">üáÆüáπ Bologna<!-- --> - <time dateTime="2025-11-05">November 5, 2025</time></dd></dl></li><li class="flex gap-4"><div class="relative mt-1 flex h-10 w-10 flex-none items-center justify-center rounded-full shadow-md shadow-zinc-800/5 ring-1 ring-zinc-900/5 dark:border dark:border-zinc-700/50 dark:bg-zinc-800 dark:ring-0"><svg class="h-6 w-6 text-zinc-400 dark:text-zinc-500" viewBox="0 0 24 24" fill="none" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z" class="fill-zinc-100 stroke-zinc-400 dark:fill-zinc-100/10 dark:stroke-zinc-500"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2" class="stroke-zinc-400 dark:stroke-zinc-500"></path><path d="M12 18v4M8 22h8" class="stroke-zinc-400 dark:stroke-zinc-500"></path></svg></div><dl class="flex flex-auto flex-wrap gap-x-2"><dt class="sr-only">Event</dt><dd class="w-full flex-none text-sm font-medium text-zinc-900 dark:text-zinc-100"><a target="_blank" rel="noopener noreferrer" href="https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/co-located-events/cncf-hosted-co-located-events-overview/">Kubecon NA - BackstageCon</a></dd><dt class="sr-only">Talk Title</dt><dd class="text-xs text-zinc-500 dark:text-zinc-400">PANEL | The Future of Developer Portals</dd><dt class="sr-only">Location and Date</dt><dd class="text-xs text-zinc-500 dark:text-zinc-400">üá∫üá∏ Atlanta, GA<!-- --> - <time dateTime="2025-11-10">November 10, 2025</time></dd></dl></li></ol></div></div></div></div></div></div></div></main><footer class="mt-32 flex-none"><div class="sm:px-8"><div class="mx-auto w-full max-w-7xl lg:px-8"><div class="border-t border-zinc-100 pb-16 pt-10 dark:border-zinc-700/40"><div class="relative px-4 sm:px-8 lg:px-12"><div class="mx-auto max-w-2xl lg:max-w-5xl"><div class="flex flex-col items-center justify-between gap-6 sm:flex-row"><div class="flex flex-wrap justify-center gap-x-6 gap-y-1 text-sm font-medium text-zinc-800 dark:text-zinc-200"><a class="transition hover:text-teal-500 dark:hover:text-teal-400" href="/about-me/">About</a><a class="transition hover:text-teal-500 dark:hover:text-teal-400" href="/projects/">Projects</a><a class="transition hover:text-teal-500 dark:hover:text-teal-400" href="/speaking/">Speaking</a></div><p class="text-sm text-zinc-500 dark:text-zinc-400">¬© <!-- -->2025<!-- --> Graziano Casto. All rights reserved.</p></div></div></div></div></div></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"pageTitle":"Graziano Casto - DevRel Engineer","pageDescription":"Welcome to the personal website of Graziano Casto.","pageLink":"https://castograziano.com","pageImage":"https://castograziano.com/casto-graziano.jpg","articles":[{"slug":"kubernetes-v134-announcement","content":"\n[Published by Kubernetes co-authored with Agustina Barbetta, Alejandro Josue Leon Bellido, Melony Qin, Dipesh Rawat](https://kubernetes.io/blog/2025/08/27/kubernetes-v1-34-release/)\n\nSimilar to previous releases, the release of Kubernetes v1.34 introduces new stable, beta, and alpha features. The consistent delivery of high-quality releases underscores the strength of our development cycle and the vibrant support from our community.\n\nThis release consists of 58 enhancements. Of those enhancements, 23 have graduated to Stable, 22 have entered Beta, and 13 have entered Alpha.\n\nThere are also some [deprecations and removals](https://kubernetes.io/blog/2025/08/27/kubernetes-v1-34-release/#deprecations-and-removals) in this release; make sure to read about those.\n\n## Release theme and logo\n\n![Kubernetes v1.34 logo: Three bears sail a wooden ship with a flag featuring a paw and a helm symbol on the sail, as wind blows across the ocean](https://kubernetes.io/blog/2025/08/27/kubernetes-v1-34-release/k8s-v1.34.png)\n\nKubernetes v1.34 logo: Three bears sail a wooden ship with a flag featuring a paw and a helm symbol on the sail, as wind blows across the ocean\n\nA release powered by the wind around us ‚Äî and the will within us.\n\nEvery release cycle, we inherit winds that we don't really control ‚Äî the state of our tooling, documentation, and the historical quirks of our project. Sometimes these winds fill our sails, sometimes they push us sideways or die down.\n\nWhat keeps Kubernetes moving isn't the perfect winds, but the will of our sailors who adjust the sails, man the helm, chart the courses and keep the ship steady. The release happens not because conditions are always ideal, but because of the people who build it, the people who release it, and the bears \u003csup\u003e^\u003c/sup\u003e, cats, dogs, wizards, and curious minds who keep Kubernetes sailing strong ‚Äî no matter which way the wind blows.\n\nThis release, **Of Wind \u0026 Will (O' WaW)**, honors the winds that have shaped us, and the will that propels us forward.\n\n\u003csub\u003e^ Oh, and you wonder why bears? Keep wondering!\u003c/sub\u003e\n\n## Spotlight on key updates\n\nKubernetes v1.34 is packed with new features and improvements. Here are a few select updates the Release Team would like to highlight!\n\n### Stable: The core of DRA is GA\n\n[Dynamic Resource Allocation](https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/) (DRA) enables more powerful ways to select, allocate, share, and configure GPUs, TPUs, NICs and other devices.\n\nSince the v1.30 release, DRA has been based around claiming devices using *structured parameters* that are opaque to the core of Kubernetes. This enhancement took inspiration from dynamic provisioning for storage volumes. DRA with structured parameters relies on a set of supporting API kinds: ResourceClaim, DeviceClass, ResourceClaimTemplate, and ResourceSlice API types under `resource.k8s.io`, while extending the `.spec` for Pods with a new `resourceClaims` field.  \nThe `resource.k8s.io/v1` APIs have graduated to stable and are now available by default.\n\nThis work was done as part of [KEP #4381](https://kep.k8s.io/4381) led by WG Device Management.\n\n### Beta: Projected ServiceAccount tokens for kubelet image credential providers\n\nThe `kubelet` credential providers, used for pulling private container images, traditionally relied on long-lived Secrets stored on the node or in the cluster. This approach increased security risks and management overhead, as these credentials were not tied to the specific workload and did not rotate automatically.  \nTo solve this, the `kubelet` can now request short-lived, audience-bound ServiceAccount tokens for authenticating to container registries. This allows image pulls to be authorized based on the Pod's own identity rather than a node-level credential.  \nThe primary benefit is a significant security improvement. It eliminates the need for long-lived Secrets for image pulls, reducing the attack surface and simplifying credential management for both administrators and developers.\n\nThis work was done as part of [KEP #4412](https://kep.k8s.io/4412) led by SIG Auth and SIG Node.\n\n### Alpha: Support for KYAML, a Kubernetes dialect of YAML\n\nKYAML aims to be a safer and less ambiguous YAML subset, and was designed specifically for Kubernetes. Whatever version of Kubernetes you use, starting from Kubernetes v1.34 you are able to use KYAML as a new output format for kubectl.\n\nKYAML addresses specific challenges with both YAML and JSON. YAML's significant whitespace requires careful attention to indentation and nesting, while its optional string-quoting can lead to unexpected type coercion (for example: [\"The Norway Bug\"](https://hitchdev.com/strictyaml/why/implicit-typing-removed/)). Meanwhile, JSON lacks comment support and has strict requirements for trailing commas and quoted keys.\n\nYou can write KYAML and pass it as an input to any version of `kubectl`, because all KYAML files are also valid as YAML. With `kubectl` v1.34, you are also able to [request KYAML output](https://kubernetes.io/docs/reference/kubectl/#syntax-1) (as in kubectl get -o kyaml ‚Ä¶) by setting environment variable `KUBECTL_KYAML=true`. If you prefer, you can still request the output in JSON or YAML format.\n\nThis work was done as part of [KEP #5295](https://kep.k8s.io/5295) led by SIG CLI.\n\n## Features graduating to Stable\n\n*This is a selection of some of the improvements that are now stable following the v1.34 release.*\n\n### Delayed creation of Job‚Äôs replacement Pods\n\nBy default, Job controllers create replacement Pods immediately when a Pod starts terminating, causing both Pods to run simultaneously. This can cause resource contention in constrained clusters, where the replacement Pod may struggle to find available nodes until the original Pod fully terminates. The situation can also trigger unwanted cluster autoscaler scale-ups. Additionally, some machine learning frameworks like TensorFlow and [JAX](https://jax.readthedocs.io/en/latest/) require only one Pod per index to run at a time, making simultaneous Pod execution problematic. This feature introduces `.spec.podReplacementPolicy` in Jobs. You may choose to create replacement Pods only when the Pod is fully terminated (has `.status.phase: Failed`). To do this, set `.spec.podReplacementPolicy: Failed`.  \nIntroduced as alpha in v1.28, this feature has graduated to stable in v1.34.\n\nThis work was done as part of [KEP #3939](https://kep.k8s.io/3939) led by SIG Apps.\n\n### Recovery from volume expansion failure\n\nThis feature allows users to cancel volume expansions that are unsupported by the underlying storage provider, and retry volume expansion with smaller values that may succeed.  \nIntroduced as alpha in v1.23, this feature has graduated to stable in v1.34.\n\nThis work was done as part of [KEP #1790](https://kep.k8s.io/1790) led by SIG Storage.\n\n### VolumeAttributesClass for volume modification\n\n[VolumeAttributesClass](https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/) has graduated to stable in v1.34. VolumeAttributesClass is a generic, Kubernetes-native API for modifying volume parameters like provisioned IO. It allows workloads to vertically scale their volumes on-line to balance cost and performance, if supported by their provider.  \nLike all new volume features in Kubernetes, this API is implemented via the [container storage interface (CSI)](https://kubernetes-csi.github.io/docs/). Your provisioner-specific CSI driver must support the new ModifyVolume API which is the CSI side of this feature.\n\nThis work was done as part of [KEP #3751](https://kep.k8s.io/3751) led by SIG Storage.\n\n### Structured authentication configuration\n\nKubernetes v1.29 introduced a configuration file format to manage API server client authentication, moving away from the previous reliance on a large set of command-line options. The [AuthenticationConfiguration](https://kubernetes.io/docs/reference/access-authn-authz/authentication/#using-authentication-configuration) kind allows administrators to support multiple JWT authenticators, CEL expression validation, and dynamic reloading. This change significantly improves the manageability and auditability of the cluster's authentication settings - and has graduated to stable in v1.34.\n\nThis work was done as part of [KEP #3331](https://kep.k8s.io/3331) led by SIG Auth.\n\n### Finer-grained authorization based on selectors\n\nKubernetes authorizers, including webhook authorizers and the built-in node authorizer, can now make authorization decisions based on field and label selectors in incoming requests. When you send **list**, **watch** or **deletecollection** requests with selectors, the authorization layer can now evaluate access with that additional context.\n\nFor example, you can write an authorization policy that only allows listing Pods bound to a specific `.spec.nodeName`. The client (perhaps the kubelet on a particular node) must specify the field selector that the policy requires, otherwise the request is forbidden. This change makes it feasible to set up least privilege rules, provided that the client knows how to conform to the restrictions you set. Kubernetes v1.34 now supports more granular control in environments like per-node isolation or custom multi-tenant setups.\n\nThis work was done as part of [KEP #4601](https://kep.k8s.io/4601) led by SIG Auth.\n\n### Restrict anonymous requests with fine-grained controls\n\nInstead of fully enabling or disabling anonymous access, you can now configure a strict list of endpoints where unauthenticated requests are allowed. This provides a safer alternative for clusters that rely on anonymous access to health or bootstrap endpoints like `/healthz`, `/readyz`, or `/livez`.\n\nWith this feature, accidental RBAC misconfigurations that grant broad access to anonymous users can be avoided without requiring changes to external probes or bootstrapping tools.\n\nThis work was done as part of [KEP #4633](https://kep.k8s.io/4633) led by SIG Auth.\n\nThe `kube-scheduler` can now make more accurate decisions about when to retry scheduling Pods that were previously unschedulable. Each scheduling plugin can now register callback functions that tell the scheduler whether an incoming cluster event is likely to make a rejected Pod schedulable again.\n\nThis reduces unnecessary retries and improves overall scheduling throughput - especially in clusters using dynamic resource allocation. The feature also lets certain plugins skip the usual backoff delay when it is safe to do so, making scheduling faster in specific cases.\n\nThis work was done as part of [KEP #4247](https://kep.k8s.io/4247) led by SIG Scheduling.\n\n### Ordered Namespace deletion\n\nSemi-random resource deletion order can create security gaps or unintended behavior, such as Pods persisting after their associated NetworkPolicies are deleted.  \nThis improvement introduces a more structured deletion process for Kubernetes [namespaces](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) to ensure secure and deterministic resource removal. By enforcing a structured deletion sequence that respects logical and security dependencies, this approach ensures Pods are removed before other resources.  \nThis feature was introduced in Kubernetes v1.33 and graduated to stable in v1.34. The graduation improves security and reliability by mitigating risks from non-deterministic deletions, including the vulnerability described in [CVE-2024-7598](https://github.com/advisories/GHSA-r56h-j38w-hrqq).\n\nThis work was done as part of [KEP #5080](https://kep.k8s.io/5080) led by SIG API Machinery.\n\n### Streaming list responses\n\nHandling large **list** responses in Kubernetes previously posed a significant scalability challenge. When clients requested extensive resource lists, such as thousands of Pods or Custom Resources, the API server was required to serialize the entire collection of objects into a single, large memory buffer before sending it. This process created substantial memory pressure and could lead to performance degradation, impacting the overall stability of the cluster.  \nTo address this limitation, a streaming encoding mechanism for collections (list responses) has been introduced. For the JSON and Kubernetes Protobuf response formats, that streaming mechanism is automatically active and the associated feature gate is stable. The primary benefit of this approach is the avoidance of large memory allocations on the API server, resulting in a much smaller and more predictable memory footprint. Consequently, the cluster becomes more resilient and performant, especially in large-scale environments where frequent requests for extensive resource lists are common.\n\nThis work was done as part of [KEP #5116](https://kep.k8s.io/5116) led by SIG API Machinery.\n\n### Resilient watch cache initialization\n\nWatch cache is a caching layer inside `kube-apiserver` that maintains an eventually consistent cache of cluster state stored in etcd. In the past, issues could occur when the watch cache was not yet initialized during `kube-apiserver` startup or when it required re-initialization.\n\nTo address these issues, the watch cache initialization process has been made more resilient to failures, improving control plane robustness and ensuring controllers and clients can reliably establish watches. This improvement was introduced as beta in v1.31 and is now stable.\n\nThis work was done as part of [KEP #4568](https://kep.k8s.io/4568) led by SIG API Machinery and SIG Scalability.\n\nPreviously, the strict validation of a Pod's DNS `search` path in Kubernetes often created integration challenges in complex or legacy network environments. This restrictiveness could block configurations that were necessary for an organization's infrastructure, forcing administrators to implement difficult workarounds.  \nTo address this, relaxed DNS validation was introduced as alpha in v1.32 and has now graduated to stable in v1.34. A common use case involves Pods that need to communicate with both internal Kubernetes services and external domains. By setting a single dot (`.`) as the first entry in the `searches` list of the Pod's `.spec.dnsConfig`, administrators can prevent the system's resolver from appending the cluster's internal search domains to external queries. This avoids generating unnecessary DNS requests to the internal DNS server for external hostnames, improving efficiency and preventing potential resolution errors.\n\nThis work was done as part of [KEP #4427](https://kep.k8s.io/4427) led by SIG Network.\n\n### Support for Direct Service Return (DSR) in Windows kube-proxy\n\nDSR provides performance optimizations by allowing return traffic routed through load balancers to bypass the load balancer and respond directly to the client, reducing load on the load balancer and improving overall latency. For information on DSR on Windows, read [Direct Server Return (DSR) in a nutshell](https://techcommunity.microsoft.com/blog/networkingblog/direct-server-return-dsr-in-a-nutshell/693710).  \nInitially introduced in v1.14, this feature has graduated to stable in v1.34.\n\nThis work was done as part of [KEP #5100](https://kep.k8s.io/5100) led by SIG Windows.\n\n### Sleep action for Container lifecycle hooks\n\nA Sleep action for containers‚Äô PreStop and PostStart lifecycle hooks was introduced to provide a straightforward way to manage graceful shutdowns and improve overall container lifecycle management.  \nThe Sleep action allows containers to pause for a specified duration after starting or before termination. Using a negative or zero sleep duration returns immediately, resulting in a no-op.  \nThe Sleep action was introduced in Kubernetes v1.29, with zero value support added in v1.32. Both features graduated to stable in v1.34.\n\nThis work was done as part of [KEP #3960](https://kep.k8s.io/3960) and [KEP #4818](https://kep.k8s.io/4818) led by SIG Node.\n\n### Linux node swap support\n\nHistorically, the lack of swap support in Kubernetes could lead to workload instability, as nodes under memory pressure often had to terminate processes abruptly. This particularly affected applications with large but infrequently accessed memory footprints and prevented more graceful resource management.\n\nTo address this, configurable per-node swap support was introduced in v1.22. It has progressed through alpha and beta stages and has graduated to stable in v1.34. The primary mode, `LimitedSwap`, allows Pods to use swap within their existing memory limits, providing a direct solution to the problem. By default, the `kubelet` is configured with `NoSwap` mode, which means Kubernetes workloads cannot use swap.\n\nThis feature improves workload stability and allows for more efficient resource utilization. It enables clusters to support a wider variety of applications, especially in resource-constrained environments, though administrators must consider the potential performance impact of swapping.\n\nThis work was done as part of [KEP #2400](https://kep.k8s.io/2400) led by SIG Node.\n\n### Allow special characters in environment variables\n\nThe environment variable validation rules in Kubernetes have been relaxed to allow nearly all printable ASCII characters in variable names, excluding `=`. This change supports scenarios where workloads require nonstandard characters in variable names - for example, frameworks like.NET Core that use `:` to represent nested configuration keys.\n\nThe relaxed validation applies to environment variables defined directly in Pod spec, as well as those injected using `envFrom` references to ConfigMaps and Secrets.\n\nThis work was done as part of [KEP #4369](https://kep.k8s.io/4369) led by SIG Node.\n\n### Taint management is separated from Node lifecycle\n\nHistorically, the `TaintManager` 's logic for applying NoSchedule and NoExecute taints to nodes based on their condition (NotReady, Unreachable, etc.) was tightly coupled with the node lifecycle controller. This tight coupling made the code harder to maintain and test, and it also limited the flexibility of the taint-based eviction mechanism. This KEP refactors the `TaintManager` into its own separate controller within the Kubernetes controller manager. It is an internal architectural improvement designed to increase code modularity and maintainability. This change allows the logic for taint-based evictions to be tested and evolved independently, but it has no direct user-facing impact on how taints are used.\n\nThis work was done as part of [KEP #3902](https://kep.k8s.io/3902) led by SIG Scheduling and SIG Node.\n\n## New features in Beta\n\n*This is a selection of some of the improvements that are now beta following the v1.34 release.*\n\n### Pod-level resource requests and limits\n\nDefining resource needs for Pods with multiple containers has been challenging, as requests and limits could only be set on a per-container basis. This forced developers to either over-provision resources for each container or meticulously divide the total desired resources, making configuration complex and often leading to inefficient resource allocation. To simplify this, the ability to specify resource requests and limits at the Pod level was introduced. This allows developers to define an overall resource budget for a Pod, which is then shared among its constituent containers. This feature was introduced as alpha in v1.32 and has graduated to beta in v1.34, with HPA now supporting pod-level resource specifications.\n\nThe primary benefit is a more intuitive and straightforward way to manage resources for multi-container Pods. It ensures that the total resources used by all containers do not exceed the Pod's defined limits, leading to better resource planning, more accurate scheduling, and more efficient utilization of cluster resources.\n\nThis work was done as part of [KEP #2837](https://kep.k8s.io/2837) led by SIG Scheduling and SIG Autoscaling.\n\n### .kuberc file for kubectl user preferences\n\nA `.kuberc` configuration file allows you to define preferences for `kubectl`, such as default options and command aliases. Unlike the kubeconfig file, the `.kuberc` configuration file does not contain cluster details, usernames or passwords.  \nThis feature was introduced as alpha in v1.33, gated behind the environment variable `KUBECTL_KUBERC`. It has graduated to beta in v1.34 and is enabled by default.\n\nThis work was done as part of [KEP #3104](https://kep.k8s.io/3104) led by SIG CLI.\n\n### External ServiceAccount token signing\n\nTraditionally, Kubernetes manages ServiceAccount tokens using static signing keys that are loaded from disk at `kube-apiserver` startup. This feature introduces an `ExternalJWTSigner` gRPC service for out-of-process signing, enabling Kubernetes distributions to integrate with external key management solutions (for example, HSMs, cloud KMSes) for ServiceAccount token signing instead of static disk-based keys.\n\nIntroduced as alpha in v1.32, this external JWT signing capability advances to beta and is enabled by default in v1.34.\n\nThis work was done as part of [KEP #740](https://kep.k8s.io/740) led by SIG Auth.\n\n### DRA features in beta\n\n#### Admin access for secure resource monitoring\n\nDRA supports controlled administrative access via the `adminAccess` field in ResourceClaims or ResourceClaimTemplates, allowing cluster operators to access devices already in use by others for monitoring or diagnostics. This privileged mode is limited to users authorized to create such objects in namespaces labeled `resource.k8s.io/admin-access: \"true\"`, ensuring regular workloads remain unaffected. Graduating to beta in v1.34, this feature provides secure introspection capabilities while preserving workload isolation through namespace-based authorization checks.\n\nThis work was done as part of [KEP #5018](https://kep.k8s.io/5018) led by WG Device Management and SIG Auth.\n\n#### Prioritized alternatives in ResourceClaims and ResourceClaimTemplates\n\nWhile a workload might run best on a single high-performance GPU, it might also be able to run on two mid-level GPUs.  \nWith the feature gate `DRAPrioritizedList` (now enabled by default), ResourceClaims and ResourceClaimTemplates get a new field named `firstAvailable`. This field is an ordered list that allows users to specify that a request may be satisfied in different ways, including allocating nothing at all if specific hardware is not available. The scheduler will attempt to satisfy the alternatives in the list in order, so the workload will be allocated the best set of devices available in the cluster.\n\nThis work was done as part of [KEP #4816](https://kep.k8s.io/4816) led by WG Device Management.\n\n#### The kubelet reports allocated DRA resources\n\nThe `kubelet` 's API has been updated to report on Pod resources allocated through DRA. This allows node monitoring agents to discover the allocated DRA resources for Pods on a node. Additionally, it enables node components to use the PodResourcesAPI and leverage this DRA information when developing new features and integrations.  \nStarting from Kubernetes v1.34, this feature is enabled by default.\n\nThis work was done as part of [KEP #3695](https://kep.k8s.io/3695) led by WG Device Management.\n\n### kube-scheduler non-blocking API calls\n\nThe `kube-scheduler` makes blocking API calls during scheduling cycles, creating performance bottlenecks. This feature introduces asynchronous API handling through a prioritized queue system with request deduplication, allowing the scheduler to continue processing Pods while API operations complete in the background. Key benefits include reduced scheduling latency, prevention of scheduler thread starvation during API delays, and immediate retry capability for unschedulable Pods. The implementation maintains backward compatibility and adds metrics for monitoring pending API operations.\n\nThis work was done as part of [KEP #5229](https://kep.k8s.io/5229) led by SIG Scheduling.\n\n### Mutating admission policies\n\n[MutatingAdmissionPolicies](https://kubernetes.io/docs/reference/access-authn-authz/mutating-admission-policy/) offer a declarative, in-process alternative to mutating admission webhooks. This feature leverages CEL's object instantiation and JSON Patch strategies, combined with Server Side Apply‚Äôs merge algorithms.  \nThis significantly simplifies admission control by allowing administrators to define mutation rules directly in the API server.  \nIntroduced as alpha in v1.32, mutating admission policies has graduated to beta in v1.34.\n\nThis work was done as part of [KEP #3962](https://kep.k8s.io/3962) led by SIG API Machinery.\n\n### Snapshottable API server cache\n\nThe `kube-apiserver` 's caching mechanism (watch cache) efficiently serves requests for the latest observed state. However, **list** requests for previous states (for example, via pagination or by specifying a `resourceVersion`) often bypass this cache and are served directly from etcd. This direct etcd access significantly increases performance costs and can lead to stability issues, particularly with large resources, due to memory pressure from transferring large data blobs.  \nWith the `ListFromCacheSnapshot` feature gate enabled by default, `kube-apiserver` will attempt to serve the response from snapshots if one is available with `resourceVersion` older than requested. The `kube-apiserver` starts with no snapshots, creates a new snapshot on every watch event, and keeps them until it detects etcd is compacted or if cache is full with events older than 75 seconds. If the provided `resourceVersion` is unavailable, the server will fallback to etcd.\n\nThis work was done as part of [KEP #4988](https://kep.k8s.io/4988) led by SIG API Machinery.\n\n### Tooling for declarative validation of Kubernetes-native types\n\nPrior to this release, validation rules for the APIs built into Kubernetes were written entirely by hand, which makes them difficult for maintainers to discover, understand, improve or test. There was no single way to find all the validation rules that might apply to an API.*Declarative validation* benefits Kubernetes maintainers by making API development, maintenance, and review easier while enabling programmatic inspection for better tooling and documentation. For people using Kubernetes libraries to write their own code (for example: a controller), the new approach streamlines adding new fields through IDL tags, rather than complex validation functions. This change helps speed up API creation by automating validation boilerplate, and provides more relevant error messages by performing validation on versioned types.  \nThis enhancement (which graduated to beta in v1.33 and continues as beta in v1.34) brings CEL-based validation rules to native Kubernetes types. It allows for more granular and declarative validation to be defined directly in the type definitions, improving API consistency and developer experience.\n\nThis work was done as part of [KEP #5073](https://kep.k8s.io/5073) led by SIG API Machinery.\n\n### Streaming informers for list requests\n\nThe streaming informers feature, which has been in beta since v1.32, gains further beta refinements in v1.34. This capability allows **list** requests to return data as a continuous stream of objects from the API server‚Äôs watch cache, rather than assembling paged results directly from etcd. By reusing the same mechanics used for **watch** operations, the API server can serve large datasets while keeping memory usage steady and avoiding allocation spikes that can affect stability.\n\nIn this release, the `kube-apiserver` and `kube-controller-manager` both take advantage of the new `WatchList` mechanism by default. For the `kube-apiserver`, this means list requests are streamed more efficiently, while the `kube-controller-manager` benefits from a more memory-efficient and predictable way to work with informers. Together, these improvements reduce memory pressure during large list operations, and improve reliability under sustained load, making list streaming more predictable and efficient.\n\nThis work was done as part of [KEP #3157](https://kep.k8s.io/3157) led by SIG API Machinery and SIG Scalability.\n\n### Graceful node shutdown handling for Windows nodes\n\nThe `kubelet` on Windows nodes can now detect system shutdown events and begin graceful termination of running Pods. This mirrors existing behavior on Linux and helps ensure workloads exit cleanly during planned shutdowns or restarts.  \nWhen the system begins shutting down, the `kubelet` reacts by using standard termination logic. It respects the configured lifecycle hooks and grace periods, giving Pods time to stop before the node powers off. The feature relies on Windows pre-shutdown notifications to coordinate this process. This enhancement improves workload reliability during maintenance, restarts, or system updates. It is now in beta and enabled by default.\n\nThis work was done as part of [KEP #4802](https://kep.k8s.io/4802) led by SIG Windows.\n\n### In-place Pod resize improvements\n\nGraduated to beta and enabled by default in v1.33, in-place Pod resizing receives further improvements in v1.34. These include support for decreasing memory usage and integration with Pod-level resources.\n\nThis feature remains in beta in v1.34. For detailed usage instructions and examples, refer to the documentation: [Resize CPU and Memory Resources assigned to Containers](https://kubernetes.io/docs/tasks/configure-pod-container/resize-container-resources/).\n\nThis work was done as part of [KEP #1287](https://kep.k8s.io/1287) led by SIG Node and SIG Autoscaling.\n\n## New features in Alpha\n\n*This is a selection of some of the improvements that are now alpha following the v1.34 release.*\n\n### Pod certificates for mTLS authentication\n\nAuthenticating workloads within a cluster, especially for communication with the API server, has primarily relied on ServiceAccount tokens. While effective, these tokens aren't always ideal for establishing a strong, verifiable identity for mutual TLS (mTLS) and can present challenges when integrating with external systems that expect certificate-based authentication.  \nKubernetes v1.34 introduces a built-in mechanism for Pods to obtain X.509 certificates via [PodCertificateRequests](https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#pod-certificate-requests). The `kubelet` can request and manage certificates for Pods, which can then be used to authenticate to the Kubernetes API server and other services using mTLS. The primary benefit is a more robust and flexible identity mechanism for Pods. It provides a native way to implement strong mTLS authentication without relying solely on bearer tokens, aligning Kubernetes with standard security practices and simplifying integrations with certificate-aware observability and security tooling.\n\nThis work was done as part of [KEP #4317](https://kep.k8s.io/4317) led by SIG Auth.\n\n### \"Restricted\" Pod security standard now forbids remote probes\n\nThe `host` field within probes and lifecycle handlers allows users to specify an entity other than the `podIP` for the `kubelet` to probe. However, this opens up a route for misuse and for attacks that bypass security controls, since the `host` field could be set to **any** value, including security sensitive external hosts, or localhost on the node. In Kubernetes v1.34, Pods only meet the [Restricted](https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted) Pod security standard if they either leave the `host` field unset, or if they don't even use this kind of probe. You can use *Pod security admission*, or a third party solution, to enforce that Pods meet this standard. Because these are security controls, check the documentation to understand the limitations and behavior of the enforcement mechanism you choose.\n\nThis work was done as part of [KEP #4940](https://kep.k8s.io/4940) led by SIG Auth.\n\n### Use.status.nominatedNodeName to express Pod placement\n\nWhen the `kube-scheduler` takes time to bind Pods to Nodes, cluster autoscalers may not understand that a Pod will be bound to a specific Node. Consequently, they may mistakenly consider the Node as underutilized and delete it.  \nTo address this issue, the `kube-scheduler` can use `.status.nominatedNodeName` not only to indicate ongoing preemption but also to express Pod placement intentions. By enabling the `NominatedNodeNameForExpectation` feature gate, the scheduler uses this field to indicate where a Pod will be bound. This exposes internal reservations to help external components make informed decisions.\n\nThis work was done as part of [KEP #5278](https://kep.k8s.io/5278) led by SIG Scheduling.\n\n### DRA features in alpha\n\n#### Resource health status for DRA\n\nIt can be difficult to know when a Pod is using a device that has failed or is temporarily unhealthy, which makes troubleshooting Pod crashes challenging or impossible.  \nResource Health Status for DRA improves observability by exposing the health status of devices allocated to a Pod in the Pod‚Äôs status. This makes it easier to identify the cause of Pod issues related to unhealthy devices and respond appropriately.  \nTo enable this functionality, the `ResourceHealthStatus` feature gate must be enabled, and the DRA driver must implement the `DRAResourceHealth` gRPC service.\n\nThis work was done as part of [KEP #4680](https://kep.k8s.io/4680) led by WG Device Management.\n\n#### Extended resource mapping\n\nExtended resource mapping provides a simpler alternative to DRA's expressive and flexible approach by offering a straightforward way to describe resource capacity and consumption. This feature enables cluster administrators to advertise DRA-managed resources as *extended resources*, allowing application developers and operators to continue using the familiar container‚Äôs `.spec.resources` syntax to consume them.  \nThis enables existing workloads to adopt DRA without modifications, simplifying the transition to DRA for both application developers and cluster administrators.\n\nThis work was done as part of [KEP #5004](https://kep.k8s.io/5004) led by WG Device Management.\n\n#### DRA consumable capacity\n\nKubernetes v1.33 added support for resource drivers to advertise slices of a device that are available, rather than exposing the entire device as an all-or-nothing resource. However, this approach couldn't handle scenarios where device drivers manage fine-grained, dynamic portions of a device resource based on user demand, or share those resources independently of ResourceClaims, which are restricted by their spec and namespace.  \nEnabling the `DRAConsumableCapacity` feature gate (introduced as alpha in v1.34) allows resource drivers to share the same device, or even a slice of a device, across multiple ResourceClaims or across multiple DeviceRequests. The feature also extends the scheduler to support allocating portions of device resources, as defined in the `capacity` field. This DRA feature improves device sharing across namespaces and claims, tailoring it to Pod needs. It enables drivers to enforce capacity limits, enhances scheduling, and supports new use cases like bandwidth-aware networking and multi-tenant sharing.\n\nThis work was done as part of [KEP #5075](https://kep.k8s.io/5075) led by WG Device Management.\n\n#### Device binding conditions\n\nThe Kubernetes scheduler gets more reliable by delaying binding a Pod to a Node until its required external resources, such as attachable devices or FPGAs, are confirmed to be ready.  \nThis delay mechanism is implemented in the [PreBind phase](https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/#pre-bind) of the scheduling framework. During this phase, the scheduler checks whether all required device conditions are satisfied before proceeding with binding. This enables coordination with external device controllers, ensuring more robust, predictable scheduling.\n\nThis work was done as part of [KEP #5007](https://kep.k8s.io/5007) led by WG Device Management.\n\n### Container restart rules\n\nCurrently, all containers within a Pod will follow the same `.spec.restartPolicy` when exited or crashed. However, Pods that run multiple containers might have different restart requirements for each container. For example, for init containers used to perform initialization, you may not want to retry initialization if they fail. Similarly, in ML research environments with long-running training workloads, containers that fail with retriable exit codes should restart quickly in place, rather than triggering Pod recreation and losing progress.  \nKubernetes v1.34 introduces the `ContainerRestartRules` feature gate. When enabled, a `restartPolicy` can be specified for each container within a Pod. A `restartPolicyRules` list can also be defined to override `restartPolicy` based on the last exit code. This provides the fine-grained control needed to handle complex scenarios and better utilization of compute resources.\n\nThis work was done as part of [KEP #5307](https://kep.k8s.io/5307) led by SIG Node.\n\n### Load environment variables from files created in runtime\n\nApplication developers have long requested greater flexibility in declaring environment variables. Traditionally, environment variables are declared on the API server side via static values, ConfigMaps, or Secrets.\n\nBehind the `EnvFiles` feature gate, Kubernetes v1.34 introduces the ability to declare environment variables at runtime. One container (typically an init container) can generate the variable and store it in a file, and a subsequent container can start with the environment variable loaded from that file. This approach eliminates the need to \"wrap\" the target container's entry point, enabling more flexible in-Pod container orchestration.\n\nThis feature particularly benefits AI/ML training workloads, where each Pod in a training Job requires initialization with runtime-defined values.\n\nThis work was done as part of [KEP #5307](https://kep.k8s.io/3721) led by SIG Node.\n\n## Graduations, deprecations, and removals in v1.34\n\n### Graduations to stable\n\nThis lists all the features that graduated to stable (also known as *general availability*). For a full list of updates including new features and graduations from alpha to beta, see the release notes.\n\nThis release includes a total of 23 enhancements promoted to stable:\n\n- [Allow almost all printable ASCII characters in environment variables](https://kep.k8s.io/4369)\n- [Allow for recreation of pods once fully terminated in the job controller](https://kep.k8s.io/3939)\n- [Allow zero value for Sleep Action of PreStop Hook](https://kep.k8s.io/4818)\n- [API Server tracing](https://kep.k8s.io/647)\n- [AppArmor support](https://kep.k8s.io/24)\n- [Authorize with Field and Label Selectors](https://kep.k8s.io/4601)\n- [Consistent Reads from Cache](https://kep.k8s.io/2340)\n- [Decouple TaintManager from NodeLifecycleController](https://kep.k8s.io/3902)\n- [Discover cgroup driver from CRI](https://kep.k8s.io/4033)\n- [DRA: structured parameters](https://kep.k8s.io/4381)\n- [Introducing Sleep Action for PreStop Hook](https://kep.k8s.io/3960)\n- [Kubelet OpenTelemetry Tracing](https://kep.k8s.io/2831)\n- [Kubernetes VolumeAttributesClass ModifyVolume](https://kep.k8s.io/3751)\n- [Node memory swap support](https://kep.k8s.io/2400)\n- [Only allow anonymous auth for configured endpoints](https://kep.k8s.io/4633)\n- [Ordered namespace deletion](https://kep.k8s.io/5080)\n- [Per-plugin callback functions for accurate requeueing in kube-scheduler](https://kep.k8s.io/4247)\n- [Relaxed DNS search string validation](https://kep.k8s.io/4427)\n- [Resilient Watchcache Initialization](https://kep.k8s.io/4568)\n- [Streaming Encoding for LIST Responses](https://kep.k8s.io/5116)\n- [Structured Authentication Config](https://kep.k8s.io/3331)\n- [Support for Direct Service Return (DSR) and overlay networking in Windows kube-proxy](https://kep.k8s.io/5100)\n- [Support recovery from volume expansion failure](https://kep.k8s.io/1790)\n\n### Deprecations and removals\n\nAs Kubernetes develops and matures, features may be deprecated, removed, or replaced with better ones to improve the project's overall health. See the Kubernetes [deprecation and removal policy](https://kubernetes.io/docs/reference/using-api/deprecation-policy/) for more details on this process. Kubernetes v1.34 includes a couple of deprecations.\n\n#### Manual cgroup driver configuration is deprecated\n\nHistorically, configuring the correct cgroup driver has been a pain point for users running Kubernetes clusters. Kubernetes v1.28 added a way for the `kubelet` to query the CRI implementation and find which cgroup driver to use. That automated detection is now **strongly recommended** and support for it has graduated to stable in v1.34. If your CRI container runtime does not support the ability to report the cgroup driver it needs, you should upgrade or change your container runtime. The `cgroupDriver` configuration setting in the `kubelet` configuration file is now deprecated. The corresponding command-line option `--cgroup-driver` was previously deprecated, as Kubernetes recommends using the configuration file instead. Both the configuration setting and command-line option will be removed in a future release, that removal will not happen before the v1.36 minor release.\n\nThis work was done as part of [KEP #4033](https://kep.k8s.io/4033) led by SIG Node.\n\n#### Kubernetes to end containerd 1.x support in v1.36\n\nWhile Kubernetes v1.34 still supports containerd 1.7 and other LTS releases of containerd, as a consequence of automated cgroup driver detection, the Kubernetes SIG Node community has formally agreed upon a final support timeline for containerd v1.X. The last Kubernetes release to offer this support will be v1.35 (aligned with containerd 1.7 EOL). This is an early warning that if you are using containerd 1.X, consider switching to 2.0+ soon. You are able to monitor the `kubelet_cri_losing_support` metric to determine if any nodes in your cluster are using a containerd version that will soon be outdated.\n\nThis work was done as part of [KEP #4033](https://kep.k8s.io/4033) led by SIG Node.\n\n#### PreferClose traffic distribution is deprecated\n\nThe `spec.trafficDistribution` field within a Kubernetes [Service](https://kubernetes.io/docs/concepts/services-networking/service/) allows users to express preferences for how traffic should be routed to Service endpoints.\n\n[KEP-3015](https://kep.k8s.io/3015) deprecates `PreferClose` and introduces two additional values: `PreferSameZone` and `PreferSameNode`. `PreferSameZone` is an alias for the existing `PreferClose` to clarify its semantics. `PreferSameNode` allows connections to be delivered to a local endpoint when possible, falling back to a remote endpoint when not possible.\n\nThis feature was introduced in v1.33 behind the `PreferSameTrafficDistribution` feature gate. It has graduated to beta in v1.34 and is enabled by default.\n\nThis work was done as part of [KEP #3015](https://kep.k8s.io/3015) led by SIG Network.\n\n## Release notes\n\nCheck out the full details of the Kubernetes v1.34 release in our [release notes](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.34.md).\n\n## Availability\n\nKubernetes v1.34 is available for download on or on the [Kubernetes download page](https://kubernetes.io/releases/download/).\n\nTo get started with Kubernetes, check out these [interactive tutorials](https://kubernetes.io/docs/tutorials/) or run local Kubernetes clusters using [minikube](https://minikube.sigs.k8s.io/). You can also easily install v1.34 using [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/).\n\n## Release Team\n\nKubernetes is only possible with the support, commitment, and hard work of its community. Each release team is made up of dedicated community volunteers who work together to build the many pieces that make up the Kubernetes releases you rely on. This requires the specialized skills of people from all corners of our community, from the code itself to its documentation and project management.\n\n[We honor the memory of Rodolfo \"Rodo\" Mart√≠nez Vega](https://github.com/cncf/memorials/blob/main/rodolfo-martinez.md), a dedicated contributor whose passion for technology and community building left a mark on the Kubernetes community. Rodo served as a member of the Kubernetes Release Team across multiple releases, including v1.22-v1.23 and v1.25-v1.30, demonstrating unwavering commitment to the project's success and stability.  \nBeyond his Release Team contributions, Rodo was deeply involved in fostering the Cloud Native LATAM community, helping to bridge language and cultural barriers in the space. His work on the Spanish version of Kubernetes documentation and the CNCF Glossary exemplified his dedication to making knowledge accessible to Spanish-speaking developers worldwide. Rodo's legacy lives on through the countless community members he mentored, the releases he helped deliver, and the vibrant LATAM Kubernetes community he helped cultivate.\n\nWe would like to thank the entire [Release Team](https://github.com/kubernetes/sig-release/blob/master/releases/release-1.34/release-team.md) for the hours spent hard at work to deliver the Kubernetes v1.34 release to our community. The Release Team's membership ranges from first-time shadows to returning team leads with experience forged over several release cycles. A very special thanks goes out to our release lead, Vyom Yadav, for guiding us through a successful release cycle, for his hands-on approach to solving challenges, and for bringing the energy and care that drives our community forward.\n\n## Project Velocity\n\nThe CNCF K8s [DevStats](https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1\u0026var-period=m\u0026var-repogroup_name=All) project aggregates a number of interesting data points related to the velocity of Kubernetes and various sub-projects. This includes everything from individual contributions to the number of companies that are contributing and is an illustration of the depth and breadth of effort that goes into evolving this ecosystem.\n\nDuring the v1.34 release cycle, which spanned 15 weeks from 19th May 2025 to 27th August 2025, Kubernetes received contributions from as many as 106 different companies and 491 individuals. In the wider cloud native ecosystem, the figure goes up to 370 companies, counting 2235 total contributors.\n\nNote that \"contribution\" counts when someone makes a commit, code review, comment, creates an issue or PR, reviews a PR (including blogs and documentation) or comments on issues and PRs.  \nIf you are interested in contributing, visit [Getting Started](https://www.kubernetes.dev/docs/guide/#getting-started) on our contributor website.\n\nSource for this data:\n\n- [Companies contributing to Kubernetes](https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1\u0026from=1747609200000\u0026to=1756335599000\u0026var-period=d28\u0026var-repogroup_name=Kubernetes\u0026var-repo_name=kubernetes%2Fkubernetes)\n- [Overall ecosystem contributions](https://k8s.devstats.cncf.io/d/11/companies-contributing-in-repository-groups?orgId=1\u0026from=1747609200000\u0026to=1756335599000\u0026var-period=d28\u0026var-repogroup_name=All\u0026var-repo_name=kubernetes%2Fkubernetes)\n\n## Event Update\n\nExplore upcoming Kubernetes and cloud native events, including KubeCon + CloudNativeCon, KCD, and other notable conferences worldwide. Stay informed and get involved with the Kubernetes community!\n\n**August 2025**\n\n- [**KCD - Kubernetes Community Days: Colombia**](https://community.cncf.io/events/details/cncf-kcd-colombia-presents-kcd-colombia-2025/): Aug 28, 2025 | Bogot√°, Colombia\n\n**September 2025**\n\n- [**CloudCon Sydney**](https://community.cncf.io/events/details/cncf-cloud-native-sydney-presents-cloudcon-sydney-sydney-international-convention-centre-910-september/): Sep 9‚Äì10, 2025 | Sydney, Australia.\n- [**KCD - Kubernetes Community Days: San Francisco Bay Area**](https://community.cncf.io/events/details/cncf-kcd-sf-bay-area-presents-kcd-san-francisco-bay-area/): Sep 9, 2025 | San Francisco, USA\n- [**KCD - Kubernetes Community Days: Washington DC**](https://community.cncf.io/events/details/cncf-kcd-washington-dc-presents-kcd-washington-dc-2025/): Sep 16, 2025 | Washington, D.C., USA\n- [**KCD - Kubernetes Community Days: Sofia**](https://community.cncf.io/events/details/cncf-kcd-sofia-presents-kubernetes-community-days-sofia/): Sep 18, 2025 | Sofia, Bulgaria\n- [**KCD - Kubernetes Community Days: El Salvador**](https://community.cncf.io/events/details/cncf-kcd-el-salvador-presents-kcd-el-salvador/): Sep 20, 2025 | San Salvador, El Salvador\n\n**October 2025**\n\n- [**KCD - Kubernetes Community Days: Warsaw**](https://community.cncf.io/events/details/cncf-kcd-warsaw-presents-kcd-warsaw-2025/): Oct 9, 2025 | Warsaw, Poland\n- [**KCD - Kubernetes Community Days: Edinburgh**](https://community.cncf.io/events/details/cncf-kcd-uk-presents-kubernetes-community-days-uk-edinburgh-2025/): Oct 21, 2025 | Edinburgh, United Kingdom\n- [**KCD - Kubernetes Community Days: Sri Lanka**](https://community.cncf.io/events/details/cncf-kcd-sri-lanka-presents-kcd-sri-lanka-2025/): Oct 26, 2025 | Colombo, Sri Lanka\n\n**November 2025**\n\n- [**KCD - Kubernetes Community Days: Porto**](https://community.cncf.io/events/details/cncf-kcd-porto-presents-kcd-porto-2025/): Nov 3, 2025 | Porto, Portugal\n- [**KubeCon + CloudNativeCon North America 2025**](https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/): Nov 10-13, 2025 | Atlanta, USA\n- [**KCD - Kubernetes Community Days: Hangzhou**](https://sessionize.com/kcd-hangzhou-and-oicd-2025/): Nov 15, 2025 | Hangzhou, China\n\n**December 2025**\n\n- [**KCD - Kubernetes Community Days: Suisse Romande**](https://community.cncf.io/events/details/cncf-kcd-suisse-romande-presents-kcd-suisse-romande/): Dec 4, 2025 | Geneva, Switzerland\n\nYou can find the latest event details [here](https://community.cncf.io/events/#/list).\n\n## Upcoming Release Webinar\n\nJoin members of the Kubernetes v1.34 Release Team on **Wednesday, September 24th 2025 at 4:00 PM (UTC)**, to learn about the release highlights of this release. For more information and registration, visit the [event page](https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cloud-native-live-kubernetes-v134-release/) on the CNCF Online Programs site.\n\n## Get Involved\n\nThe simplest way to get involved with Kubernetes is by joining one of the many [Special Interest Groups](https://github.com/kubernetes/community/blob/master/sig-list.md) (SIGs) that align with your interests. Have something you‚Äôd like to broadcast to the Kubernetes community? Share your voice at our weekly [community meeting](https://github.com/kubernetes/community/tree/master/communication), and through the channels below. Thank you for your continued feedback and support.\n\n- Follow us on Bluesky [@Kubernetesio](https://bsky.app/profile/kubernetes.io) for the latest updates\n- Join the community discussion on [Discuss](https://discuss.kubernetes.io/)\n- Join the community on [Slack](http://slack.k8s.io/)\n- Post questions (or answer questions) on [Stack Overflow](http://stackoverflow.com/questions/tagged/kubernetes)\n- Share your Kubernetes [story](https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform)\n- Read more about what‚Äôs happening with Kubernetes on the [blog](https://kubernetes.io/blog/)\n- Learn more about the [Kubernetes Release Team](https://github.com/kubernetes/sig-release/tree/master/release-team)","metadata":{"title":"Kubernetes v1.34: Of Wind \u0026 Will (O' WaW)","excerpt":"Kubernetes v1.34 introduces 58 enhancements including 23 stable features, from Dynamic Resource Allocation (DRA) GA to KYAML support. Discover the latest improvements in security, scheduling, and resource management in this comprehensive release.","date":"2025-08-27","author":"Graziano Casto"}},{"slug":"ephemetal-cloud-with-crossplane-and-kubegreen","content":"\n[Published by DZONE](https://dzone.com/articles/infrastructure-crossplane-kube-green)\n\nWe were all sold a compelling vision of cloud computing: one filled with agility, endless scalability, and remarkable cost savings. Yet, for many of us in the trenches, the daily reality looks quite different. We find ourselves wrestling with an infrastructure model built on long-lived, static environments for development, testing, and staging. This old way of working has quietly become a massive drain on our resources, creating financial waste, operational headaches, and a growing list of security and environmental debts.\n\nThis isn't just one problem; it's a vicious cycle. The friction in our daily operations directly fuels the financial, security, and environmental burdens. To break free, we need more than just a new tool; we need to fundamentally rethink how we provision, manage, and consume infrastructure.\n\n## The High Cost of 'Always-On'\n\nThe most obvious symptom of this broken model is the money it wastes. It's not a small number; research suggests a staggering [30-45% of all cloud spending is wasted on idle or over-provisioned resources](https://42on.com/the-hidden-costs-of-cloud-waste-how-to-optimize-your-cloud-resources-and-reduce-environmental-impact/). This isn't surprising when you think about it. Our staging, UAT, and dev environments are built to handle peak loads, but they spend most of their lives (nights, weekends, holidays) doing absolutely nothing. This leads to an abysmal average CPU utilization of just 12-15%, a clear sign that something is deeply inefficient. This problem is made worse by \"cloud sprawl\", where new resources pop up uncontrolled, increasing costs, security holes, and complexity.\n\nThis financial drain is a direct result of operational friction. Many of us are familiar with the \"ticket-driven\" culture: a developer needs an environment, so they file a ticket and wait. And wait. This manual, slow process creates bottlenecks that grind the entire development lifecycle to a halt. In a world of complex microservices, setting these environments up by hand isn't just slow; it's a recipe for errors. This model encourages us to keep these costly, complex environments running indefinitely, because tearing them down and rebuilding them is just too painful.\n\nThis persistence creates a huge security risk. Over time, these static environments suffer from \"configuration drift.\" Manual tweaks, untracked updates, and inconsistent patching mean they no longer match production or even each other. They become, as one source aptly put it, a [\"hive of duplicated data, exploitable vulnerabilities, and misconfigurations\"](https://www.quali.com/glossary/ephemeral-environments/). Each one is a persistent attack surface, a liability that only grows with time.\n\n## The Unseen Environmental Toll\n\nThe money we waste on idle resources is just the tip of the iceberg. Under the surface lies a massive, often ignored, environmental cost. Every idle virtual machine or database isn't just a line item on a bill; it's a physical server in a data center, burning electricity and pumping out CO2 for no reason. Data centers already consume about [1% of the world's electricity](https://www.researchgate.net/publication/390569272_The_Environmental_Impact_of_Cloud_Computing_Sustainability_in_the_Cloud), and that number is only going up.\n\nTo put this in perspective, a 2019 study found that training a single large AI model can produce the same carbon emissions as [more than 300 cross-country flights](https://www.forbes.com/councils/forbestechcouncil/2025/02/20/the-unsung-mechanics-how-ai-and-cloud-integration-drive-the-engine-of-sustainability/). This is the energy cost of our digital world. Beyond emissions, there's e-waste from constant hardware upgrades and the immense amount of water used for cooling. While cloud providers are more efficient than on-premise data centers, the core problem remains: we, the customers, are provisioning resources that sit idle, driving unnecessary environmental impact.\n\nLet's make this real. Imagine a team of 10 engineers with a single, static staging environment. It runs 24/7, but they only use it for about 160 hours a month. For the other 560 hours, nearly 78% of the time, it's idle but still racking up costs. Using the CO2 calculator from the [kube-green project](https://kube-green.dev/), which assumes that a single pod produces about [11 kg of CO2eq per year](https://kube-green.dev/docs/FAQ/#how-much-co2-is-produced-by-a-pod), we can see the impact. If that staging environment runs 20 pods, it generates 220 kg of CO2eq annually. By simply shutting it down when it's idle, the team could prevent over 170 kg of CO2eq emissions. Now, scale that across an entire organization. The waste is enormous.\n\n## The Ephemeral Revolution\n\nThis is where a new idea comes in: the ephemeral environment. It‚Äôs a complete shift in thinking. Instead of permanent, long-lived infrastructure, we move to on-demand, temporary workspaces that directly combat waste and friction. An ephemeral environment is a short-lived, isolated, and complete copy of your application, spun up for a specific task and automatically destroyed when you're done.\n\nThis approach is built on a few key ideas. First, it's **on-demand and automated**. Environments are created by events in your workflow, like opening a pull request, not by filing a ticket. What once took days now takes minutes. Second, each environment is **completely isolated**. This means no more \"who broke the staging server?\" A developer can test a new feature, run a database migration, or experiment with a dependency without affecting anyone else. This enables true parallel development.\n\nCrucially, these are not just simple \"preview environments\". A true ephemeral environment achieves **production-parity**. It‚Äôs a full-fidelity clone of your production stack: backend services, databases, configurations, everything. This is how you kill the \"it works on my machine\" problem for good. Finally, these environments are both **shareable and disposable**. You get a unique URL to share with stakeholders for feedback on a live, running feature. When the pull request is merged, the entire environment is wiped away as if it never existed. This disposable nature is the key to its efficiency.\n\nAdopting this model has a transformative impact. It dramatically boosts developer velocity by removing bottlenecks. Some organizations have seen [delivery times improve by up to 35%](https://ephemeralenvironments.io/) and overall velocity increase by as much as 10x. It fosters better collaboration because everyone, from product managers to QA, can interact with a tangible, running feature, not just mockups. This \"shift-left\" approach to testing also means you catch bugs earlier, significantly improving code quality and reducing the risk of production failures. The old static staging environment is a relic of an old era: costly, slow, and risky. The ephemeral model is its opposite: on-demand, fast, safe, and efficient.\n\n## The Technology Pillars: Crossplane and kube-green\n\nThis vision of a fully ephemeral cloud requires the right technology. You need to be able to programmatically control not just your application containers, but the entire infrastructure ecosystem: databases, networks, storage, and more. This is where two key open-source projects come into play: Crossplane and kube-green.\n\nCrossplane is the heart of this architecture. It‚Äôs a universal control plane that extends the Kubernetes API to manage any cloud resource, not just containers. This represents a profound shift from traditional [Infrastructure as Code (IaC)](https://dzone.com/articles/what-is-infrastructure-as-code) tools like Terraform to a new model: [Infrastructure as Data (IaD)](https://medium.com/@swarupdonepudi/infrastructure-as-data-iad-coincidence-2ca6c70f896e).\n\nWith traditional IaC, you run a command like terraform apply to make a one-time change. With Crossplane, you declare the desired state of your infrastructure in a YAML file and submit it to the Kubernetes API. From then on, Crossplane's controllers work continuously to ensure reality matches your declaration. If anything drifts, Crossplane automatically corrects it. This \"self-healing\" capability is a game-changer.\n\nIt works through a clever, layered architecture. **Providers** teach Crossplane how to talk to a specific API, like AWS or GCP. **Managed Resources** are the building blocks, representing a single piece of infrastructure like an S3 bucket or an RDS database. But the real magic is in **Compositions**. A platform team can use a Composition to bundle all the necessary Managed Resources into a single, high-level abstraction, like a PostgreSQLInstance. This blueprint can embed all the company's best practices for security, networking, and compliance.\n\nDevelopers don't need to worry about that complexity. They simply request what they need by creating a **Claim**: a simple YAML asking for a PostgreSQLInstance for example. Crossplane sees the claim and provisions the entire, production-ready stack automatically. This is true developer self-service, and it's exactly what's needed for ephemeral environments. When a pull request is opened, a CI/CD pipeline can create a single Claim that tells Crossplane to spin up a dedicated database, message queue, and everything else the application needs. When the PR is closed, deleting that one Claim tears it all down.\n\nWhile Crossplane manages the existence of the environment, [kube-green](https://kube-green.dev/) handles the efficiency within that existence. An ephemeral environment might live for a few days, but developers aren't working on it 24/7. kube-green is a simple, brilliant utility that solves this \"last mile\" problem by automatically hibernating resources on a schedule.\n\nIt operates as a Kubernetes operator that you configure with a **SleepInfo** resource in each namespace. You can tell it to shut things down at 8 PM on weekdays and wake them up at 8 AM, for example. When the sleep time hits, kube-green scales down your Deployments and suspends your CronJobs. When the wake-up time arrives, it brings everything back to its original state. This simple action can lead to huge savings. Adopters have reported [30-40% reductions in cloud costs](https://kube-green.dev/docs/adopters/) for non-production clusters. And because it reduces energy consumption, it has a direct, positive impact on your carbon footprint.\n\n## The Synthesis: A New Blueprint for Efficiency\n\nWhen you combine Crossplane's strategic, full-stack orchestration with kube-green's tactical, time-based optimization, you get something truly powerful. This synergy creates a multi-layered system of efficiency that aligns your infrastructure cost and carbon footprint with the actual, value-generating work of your development teams.\n\nThe workflow, driven by GitOps tools like ArgoCD, is beautifully simple. A developer opens a pull request. This triggers a CI pipeline that generates the manifests for the new environment, including a Crossplane Claim for the infrastructure and a kube-green SleepInfo for the schedule. These manifests are committed to a Git repository. ArgoCD sees the new files and applies them to your management cluster. Crossplane springs into action, provisioning the entire infrastructure stack, perhaps in a lightweight vCluster for perfect isolation. Once the infrastructure is ready, ArgoCD deploys the application code. When the PR is merged or closed, a CI job removes the manifests from Git, and the entire environment vanishes.\n\nThis creates a two-tiered optimization model. **Macro-optimization** from Crossplane ensures you only pay for infrastructure for the few days a PR is active, not for a permanent staging environment. **Micro-optimization** from kube-green then eliminates waste within that short lifespan by hibernating resources during non-working hours.\n\nThis points to an exciting point: a \"deep sleep\" model. Using kube-green's ability to patch any Kubernetes resource, you could have it not only scale down pods but also patch the Crossplane Claim itself, for example, telling it to scale a database cluster down to a single, low-cost node overnight. This would extend time-based optimization to the entire stateful infrastructure stack, achieving the ultimate form of on-demand efficiency.\n\n## Getting Started on Your Journey\n\nWhile this vision of a fully automated, per-PR ephemeral world is the goal, you don't have to build it all at once. The journey can start with a single, high-impact step. To make these concepts tangible, I've put together a [hands-on tutorial](https://github.com/graz-dev/crossplane-ephemeral-environments) that focuses on a pragmatic starting point: creating on-demand infrastructure that's only active when you need it.\n\nThe tutorial walks you through using Crossplane to provision an AWS EKS cluster and then using kube-green to put it on a sleep/wake schedule. It's a direct, practical way to tackle the biggest source of waste: idle resources.\n\nIf this vision for a more efficient cloud resonates with you, the best way to understand it is to build it. I invite you to check out the tutorial, [Ephemeral Cloud Resources with Crossplane and kube-green](https://github.com/graz-dev/crossplane-ephemeral-environments). Dive in, experiment with the code, and see the benefits for yourself. If you find it valuable, please give the repository a star on GitHub and share this article with your network.\n\n## A Strategic Outlook for the Future\n\nThe shift to an ephemeral cloud model is more than a technical upgrade; it's a strategic evolution. It allows us to move from passively managing static resources to actively orchestrating dynamic, value-generating capabilities. The future of this model is even more exciting, driven by AI-powered optimization and the formalization of GreenOps.\n\nNew AI tools like StormForge and CAST AI are emerging that can analyze workloads to automatically tune resource configurations and predict demand. Imagine an AI that could predict a PR's review cycle to allocate resources more intelligently or manage energy use based on the real-time carbon intensity of the power grid.\n\nThis model is also a foundational practice for GreenOps, the discipline of bringing environmental accountability to cloud operations. As sustainability becomes a key business metric, the ability to measure and minimize the carbon footprint of software development will be a major differentiator.\n\nFor technology leaders, the path forward is clear. Treat your internal infrastructure as a product and invest in a platform team to build out this capability. Foster a culture of accountability by making cost and carbon data transparent to your engineering teams. And start small. Pick a single service and use it as a pilot project to prove the value and build expertise.\n\nThe combination of Crossplane and kube-green offers a powerful and pragmatic toolkit to begin this journey. By adopting this new blueprint, you can accelerate innovation while dramatically reducing your financial and environmental costs.","metadata":{"title":"The Ephemeral Cloud: A New Blueprint for Infrastructure Efficiency With Crossplane and kube-green","excerpt":"Use Crossplane and kube-green to replace wasteful, always-on cloud environments with on-demand, ephemeral ones, dramatically cutting costs and environmental impact.","date":"2025-08-25","author":"Graziano Casto"}},{"slug":"kcd-nyc-pe-observability-roundtable","content":"\n[Published by Cloud Native PE Community](https://cloudnativeplatforms.com/blog/kcd-nyc-platform-engineering-and-observability-roundtable/)\n\n\u003e There was a great energy at KCD New York this year, and for Graziano Casto, a personal highlight was leading a roundtable on observability. It was a fascinating discussion that really got him thinking about the challenges we‚Äôre all facing in the platform engineering space. Here is Graziano‚Äôs recap of the key problems and promising ideas that came up.\n\n### Introduction\n\nIt was an absolute pleasure recently to moderate a roundtable at [KCD New York](https://community.cncf.io/events/details/cncf-kcd-new-york-presents-kcd-new-york-2025/), diving deep into the fascinating (and let‚Äôs be honest, sometimes frustrating) world where **Platform Engineering meets Observability**. As my first time moderating a roundtable, I was genuinely thrilled by the energy and candid participation from everyone in the room. A huge thank you to all the participants: [Michel Murabito](https://www.linkedin.com/in/mich-murabito/), [Colin Lacy](https://www.linkedin.com/in/colinjlacy/), [Tiara Sykes](https://www.linkedin.com/in/tiara-sykes/), [Andrew Espira](https://www.linkedin.com/in/andrew-espira/), [Mariia Rudenko](https://www.linkedin.com/in/mariia-r-748931163/), [Aderianna Williams](https://www.linkedin.com/in/at-williams/), [Marino Wijay](https://www.linkedin.com/in/mwijay/) and [Maria Ashby](https://www.linkedin.com/in/maria-ashby/) whose insights made this discussion truly invaluable. We had an incredibly insightful exchange, and I walked away with some serious food for thought.\n\n![](../../assets/newsletter/12-kcd-new-york/photo-4.jpeg)\n\nWe kicked off by acknowledging a universal truth in today‚Äôs cloud-native landscape: managing a full observability stack often feels like trying to hit a moving target. The more we aim to observe, the more inherent complexity seems to creep in. We continuously pile on tools, data, and dashboards‚Äìbe it metrics, traces, logs, or profiling ‚Äì and suddenly, we‚Äôre swimming in a sea of cognitive load, entropy, and quite often, plain old confusion. So, instead of me listing the common headaches, I threw it open to the room: ‚ÄúWhen you think about managing a full observability stack, across logs, metrics, traces, and so on, what are your biggest pain points? If you had to name the biggest challenge your team is facing with observability right now, what would it be?‚Äù\n\nThe responses flowed freely, revealing a shared understanding that while observability promises clarity, its real-world implementation often introduces its own unique set of challenges. And, quite organically, our conversation drifted into the exciting (and slightly unsettling) realm of Generative AI, specifically discussing how Large Language Models (LLMs) can be synergistically integrated within platforms to serve as enablers in resolving some of these very challenges.\n\n### The Observability Headaches: Where Do We Feel the Pinch?\n\nOne of the loudest points of contention was the persistent struggle to correlate telemetry data with the actual services generating them, and the broader challenge of **telemetry data correlation**. It‚Äôs like having all the pieces of a complex puzzle but no clear idea how they fit together. You might spot a spike in CPU utilization ‚Äì a metric ‚Äì but then you‚Äôre left guessing which microservice is the culprit. Then begins the detective work: diving into logs to pinpoint an error, and finally tracing requests to understand the flow. The fundamental problem is that these critical data points often reside in disparate systems, use inconsistent identifiers, and demand a significant amount of manual effort and intuition to connect the dots. This fragmentation makes it incredibly difficult to quickly identify the root cause of a problem when seconds count.\n\nAdding to this complexity is the sheer volume of alerts and the difficulty in correlating them with the actual underlying problem. We‚Äôve all experienced it: a dozen alerts fire simultaneously, each pointing to a symptom, yet none clearly indicating the core issue. This leads to what‚Äôs known as **alert fatigue**, resulting in missed critical incidents, wasted time triaging false positives, and ultimately, a palpable loss of trust in the alerting system itself. The challenge isn‚Äôt merely about receiving notifications; it‚Äôs about receiving meaningful alerts that directly pinpoint the underlying problem, not just its outward manifestations.\n\nFurthermore, a significant unspoken burden that often comes with observability is the **cost** of both creating and maintaining the entire observability stack. From licensing fees for proprietary tools to the infrastructure costs of storing massive volumes of telemetry data and the operational overhead of managing these complex systems, the financial outlay can be substantial. This constant investment of resources, both human and monetary, can become a major pain point, often weighing heavily on budget decisions and resource allocation.\n\nThen there‚Äôs the pervasive issue of **making insights accessible** and visualizing them in a way that provides the right insight to the right person. Raw telemetry data, in its unadulterated form, is overwhelming. Different roles within an organization ‚Äì SREs, developers, product managers ‚Äì need distinct views and varying levels of detail. A developer might require granular trace data, while a product manager needs high-level business metrics. The constant battle involves creating and maintaining these tailored dashboards and ensuring everyone knows where to find what they need. This often leads to information silos and missed opportunities for proactive improvement.\n\nA recurring theme throughout our discussion was the persistent problem of **siloed teams** and the resulting **lack of standardization**. When different teams adopt disparate observability tools, inconsistent naming conventions, or even varied logging formats, it inevitably creates a fragmented and chaotic landscape. This makes it incredibly challenging to gain a holistic view of the system, collaborate effectively during incidents, and leverage best practices across the entire organization. It‚Äôs a classic case of ‚Äúeveryone doing their own thing‚Äù, leading to pervasive inefficiencies and increased complexity.\n\nFinally, a crucial point that resonated deeply was the importance of **developer education**. Observability isn‚Äôt merely about deploying tools; it‚Äôs about cultivating a specific mindset. Developers need to grasp why observability is vital, how to effectively instrument their code, how to interpret telemetry data, and critically, how to leverage observability tools to troubleshoot their applications. This knowledge gap can lead to poorly instrumented services, ignored alerts, and a general underutilization of the powerful observability stacks organizations invest heavily in.\n\n### Internal Developer Platforms: The Unified Solution\n\nSo, with these common headaches laid out, how do we begin to alleviate them? This is precisely where the concept of an **Internal Developer Platform (IDP)** steps in as a truly powerful solution, providing a cohesive answer to many of these challenges.\n\nAn IDP, at its core, inherently solves the problem of standardization. By providing clear standards and abstractions through ‚Äúgolden paths‚Äù for building and deploying applications, it ensures consistency across the organization. However, it‚Äôs crucial that these **golden paths** don‚Äôt become ‚Äúgolden cages‚Äù. A well-designed IDP empowers developers with the necessary autonomy to cover edge cases, allowing them to step outside the perimeter of the provided golden paths when needed for specific requirements. This balance is vital for both consistency and innovation.\n\nMoving beyond standardization, IDPs also play a crucial role in addressing the challenges faced by siloed teams that might be working on different components of the same system and often lack a shared performance baseline. During our discussion, we introduced the concept of leveraging generative models within these platforms. Specifically, the role of Generative AI, particularly **Large Language Models (LLMs)**, in the observability space emerged as a truly futuristic and exciting prospect. The idea is that LLMs can help close the gap between users and telemetry data. Imagine being able to ask natural language questions like, ‚ÄúWhy is our checkout service slow right now?‚Äù and have an LLM sift through mountains of metrics, logs, and traces to provide a concise, actionable answer. Or, ‚ÄúWhat were the top 3 errors in our authentication service last night?‚Äù and get a summary, perhaps even with links to relevant log lines. These models can also be instrumental in enabling teams to define and compare their telemetry data against customized thresholds, ensuring that the entire system is monitored according to a collectively defined baseline, fostering a shared understanding of system health.\n\nFrom here, we delved into how these models further enhance the transparency and clarity of insights. LLMs, integrated within the IDP, can analyze vast amounts of telemetry data and provide various stakeholders with personalized insights and alerts. This capability opens the door to entirely new interfaces beyond the traditional dashboards, making complex operational data more accessible and actionable for different roles. Unfortunately, we didn‚Äôt have the opportunity to delve deeper into the intricate topic of telemetry data correlation during the roundtable, but I have written an article that explores this topic further, which you can find [here](https://www.linkedin.com/pulse/9-serving-observability-first-dish-graziano-casto-05rhf).\n\n### The Open Question: Balancing Trust and Cost with Benefits in the LLM Era\n\nHowever, as with any powerful new technology, the discussion around LLMs quickly led to a critical open question for the community:\n\n**How do we effectively balance the significant benefits that LLMs bring ‚Äì such as improved automation and deeper insights ‚Äì against the inherent costs? These costs include not only the economic investment required for these models but also the crucial aspect of trust, both in the accuracy of the results and in entrusting our sensitive data to an LLM, particularly when utilized as a service.**\n\nThis is a conversation that needs to continue. As we push the boundaries of what‚Äôs possible with AI in operations, we must collectively figure out how to build systems that are not only efficient and intelligent but also fundamentally secure, trustworthy, and cost-effective.\n\n### Wrapping Up\n\nMy first moderating experience at KCD New York was an absolute blast, and the insights from the roundtable on Platform Engineering and Observability were truly invaluable. It‚Äôs clear that while observability brings its own set of complexities, Internal Developer Platforms offer a robust framework for overcoming these challenges by promoting standardization, providing contextualized insights, and empowering developers. And looking ahead, the potential of LLMs to revolutionize how we interact with our telemetry data is incredibly exciting, even if it comes with some important questions we need to answer as a community.\n\nWhat are your thoughts on these challenges and solutions? And how do you see the role of LLMs evolving in the observability space, especially concerning the trust and cost trade-offs? Let‚Äôs keep the conversation going!\n","metadata":{"title":"From Chaos to Clarity: Navigating Observability in the Platform Engineering Era (and a Dash of AI)","excerpt":"A comprehensive recap of the KCD New York roundtable discussion on Platform Engineering and Observability, exploring key challenges, solutions, and the role of AI in modern observability practices.","date":"2025-08-20","author":"Graziano Casto"}},{"slug":"wasm-next-universal-runtime","content":"\n[Published by DZONE co-authored with Alex Casalboni (Developer Advocate @ Edgee)](https://dzone.com/articles/webassembly-from-browser-plugin-to-the-next-univer)\n\n\nFor decades, the digital world has converged on a single, universal computing platform: the web browser. This remarkable piece of software, present on nearly every device, promised a \"write once, run anywhere\" paradigm, but with a crucial limitation, it only spoke one language natively: JavaScript. While incredibly versatile, JavaScript's nature as a dynamically typed, interpreted language created a performance ceiling. For computationally intensive tasks, developers often hit a wall, unable to achieve the raw speed of native applications. This limitation also meant that the vast, mature ecosystems of code written in languages like C++, C, and Rust were largely inaccessible on the web without cumbersome and often inefficient cross-compilation to JavaScript.\n\nInto this landscape emerged [**WebAssembly**](https://dzone.com/articles/what-is-webassembly) **(Wasm)**. Often referred to as a fourth standard language for the web alongside HTML, CSS, and JavaScript, Wasm was not designed to replace JavaScript but to be its powerful companion. It is a binary instruction format, a low-level, assembly-like language that **serves as a portable compilation target**. This simple yet profound idea meant that developers could take existing code written in high-performance languages, compile it into a compact Wasm binary, and run it directly within the browser at near-native speeds. This breakthrough unlocked a new class of applications that were previously impractical for the web, from sophisticated in-browser tools to full-fledged 3D gaming engines.\n\nThe design of WebAssembly was forged in the demanding and often hostile environment of the public internet, leading to a set of foundational principles that would define its destiny. It had to be **fast**, with a compact binary format that could be decoded and executed far more efficiently than parsing text-based JavaScript. It had to be **secure**, running inside a tightly controlled, memory-safe sandbox that isolated it from the host system and other browser tabs. And it had to be **portable**, a universal format independent of any specific operating system or hardware architecture.\n\nThese very principles, essential for its success in the browser, were also the seeds of a much grander vision. This article charts the remarkable journey of WebAssembly, following its evolution from a browser-based performance booster into a foundational technology that is reshaping our approach to cloud, edge, and distributed computing, promising a future built on a truly universal runtime.\n\n### Beyond the Browser With the WebAssembly System Interface (WASI)\n\nWebAssembly's potential was too significant to remain confined within the browser. Developers and architects quickly recognized that a portable, fast, and secure runtime could be immensely valuable for server-side applications. However, a critical piece of the puzzle was missing.\n\nWasm modules running in the browser can interact with its environment through a rich set of Web APIs, allowing it to fetch data, manipulate the screen, or play audio. Server-side applications have a **completely different set of needs**: they must read and write files, access environment variables, open network sockets, and interact with the system clock. Without a standardized way to perform these basic operations, server-side Wasm would be a collection of incompatible, proprietary solutions, shattering its promise of portability.\n\nThe solution is the **WebAssembly System Interface (WASI)**, an evolving set of APIs. It's crucial to understand that WASI is not a single, monolithic standard but is currently in a significant transition, from the stable but limited **WASI Preview 1** (which lacks standardized networking) to the fundamentally redesigned **WASI Preview 2**. This newer version is built upon the still-in-proposal Component Model and introduces modular APIs for features like HTTP and sockets. ¬†Looking ahead, the next iteration, [WASI Preview 3](https://wasi.dev/roadmap#upcoming-wasi-03-releases), is anticipated for release in **August 2025**, promising further advancements such as native async and streaming support.\n\nThis layer of abstraction is the key to preserving Wasm's \"write once, run anywhere\" superpower. The WASI standard allows developers to write code in their preferred programming language (including [Rust](https://dzone.com/articles/rust-and-webassembly-for-web-apps), C/C++, C#, Go, JavaScript, TypeScript, and Python), compile it into a single Wasm binary, and run it on any operating system or CPU architecture using a compliant runtime.. In the browser, the JavaScript engine acts as the host runtime; outside the browser, this role is filled by standalone runtimes such as Wasmtime, Wasmer, or WasmEdge, which implement the WASI standard to provide secure access to system resources.\n\nMore than just enabling server-side execution, WASI introduced a fundamentally different and more secure way for programs to interact with the system. Traditional applications, following a model established by POSIX, typically inherit the permissions of the user who runs them. If a user can access a file, any program they run can also access that file, which creates a broad and implicit grant of authority.\n\nWASI, in contrast, implements a **capability-based security model**. By default, a Wasm module running via WASI can do nothing. It has no access to the filesystem, no ability to make network connections, and no visibility into system clocks or environment variables. To perform any of these actions, the host runtime must explicitly grant the module a 'capability'. For example, to allow a module to read files, the host must grant it a capability for a specific directory. The module receives a handle to that directory and can operate only within its confines. Any attempt to access a path outside of it will fail at the runtime level with a 'permission denied' error, even if the user running the process has permissions for that file. This enforces the **Principle of Least Privilege** at a granular level, a stark contrast to the traditional POSIX model where a process inherits all the ambient permissions of the user.\n\nThis \" *deny-by-default* \" posture represents a paradigm shift in application security. The decision to build WASI around a capability-based model was not merely a technical convenience; it was a deliberate architectural choice that transformed Wasm from a simple performance tool into a foundational building block for trustworthy computing. The browser sandbox provided an implicit security boundary designed to protect users from malicious websites. Simply mirroring traditional OS permissions on the server would have compromised this security-first ethos. Instead, by externalizing permission management from the application to the host runtime, WASI makes security an explicit, auditable contract.\n\nThis has profound implications, making Wasm uniquely suited for scenarios where the code being executed cannot be fully trusted. This includes multi-tenant serverless platforms running customer-submitted functions, extensible applications with third-party plugin systems, and edge devices executing logic from various sources. WASI did not just allow Wasm to run on the server; it defined how it would run: securely, with granular permissions, and by default, with no authority at all.\n\n### A Different Kind of Isolation: Wasm vs. Containers\n\nFor many developers today, the container has become the default unit of application deployment, a standardized box for packaging and running software. The rise of WebAssembly has introduced a new model, prompting a comparison that is less about which technology is superior and more about understanding two fundamentally different philosophies for achieving portability and isolation.\n\nThe container philosophy centers on porting the entire **environment**. A container image, such as one built with [Docker](https://dzone.com/articles/docker-use-cases-15-most-common-ways-to-use-docker), packages an application along with a complete slice of its user-space operating system: a filesystem, system libraries, configuration files, and all other dependencies. It achieves isolation from the host and other containers by leveraging OS-level virtualization features, primarily Linux namespaces and control groups (cgroups), which create the illusion of a private machine. The container's promise is that this self-contained environment will run consistently everywhere a container engine is installed.\n\nThe WebAssembly philosophy, in contrast, is about porting only the **application logic**. A Wasm module is a single, self-contained binary file containing just the compiled application code. It brings no operating system, no filesystem, and no system bundled libraries. Instead, it relies on the host runtime to provide a standardized environment and to mediate access to system resources through the WASI interface. Wasm's promise is that the application logic, compiled once, will run consistently everywhere a compliant Wasm runtime is present.\n\nThis philosophical divergence leads to significant practical trade-offs in size, speed, and security. Because a container must package a slice of an operating system, its image size is measured in (hundreds of) megabytes, even for simple applications. A Wasm module, containing only the application code, is orders of magnitude smaller, typically measured in kilobytes or a few megabytes. This dramatic difference impacts everything from storage costs and network transfer times to the density of workloads that can run on a single machine.\n\nThe most critical distinction, particularly for modern cloud architectures, is startup speed. A container must initialize its packaged environment: a process that involves setting up namespaces, mounting the filesystem, and booting the application. This \"cold start\" can take hundreds of milliseconds, or even several seconds. A Wasm module, on the other hand, is instantiated by an already-running runtime, a process that can take less than a millisecond (for compiled languages like Rust, C or Go). This near-instantaneous startup effectively eliminates the cold start problem, making Wasm an ideal technology for event-driven, scale-to-zero architectures like serverless functions, where responsiveness is paramount.\n\nThe security models also differ profoundly. Containers provide isolation at the OS kernel level. This means all containers on a host share the same kernel, which represents a large and complex attack surface. Security vulnerabilities often center on kernel exploits or misconfigurations that allow a process to \"escape\" its container and gain access to the host system. WebAssembly introduces an additional, finer-grained layer of isolation: the application-level sandbox. The attack surface is not the entire OS kernel, but the much smaller and more rigorously defined boundary of the Wasm runtime and the WASI interface. Combined with its capability-based security model, this makes Wasm \"secure by default\" and a far safer choice for running untrusted or third-party code.\n\n| Feature                 | **WebAssembly (WASM)**                                              | **Containers**                                                   |\n| ----------------------- | ------------------------------------------------------------------- | ---------------------------------------------------------------- |\n| **Unit of Portability** | Application Logic (a `.wasm` binary)                                | Application Environment (an OCI image with an OS filesystem)     |\n| **Isolation Model**     | Application-level Sandbox (deny-by-default)                         | OS-level Virtualization (namespaces, cgroups)                    |\n| **Security Boundary**   | Wasm Runtime \u0026 WASI Interface (small, well-defined)                 | Host OS Kernel (large, complex attack surface)                   |\n| **Startup Time**        | Sub-millisecond (\"zero cold start\")                                 | Hundreds of milliseconds to seconds (\"cold start\" problem)       |\n| **Size / Footprint**    | Kilobytes to Megabytes                                              | Megabytes to Gigabytes                                           |\n| **Platform Dependency** | Runtime-dependent (any OS/arch with a Wasm runtime)                 | OS and Architecture-dependent (e.g. `linux/amd64`)               |\n| **Ideal Use Case**      | Serverless functions, microservices, edge computing, plugin systems | Lift-and-shift legacy apps, complex stateful services, databases |\n\nUltimately, these two technologies are not adversaries but complements. It is common to run Wasm workloads inside containers as a first step toward integrating them into existing infrastructure. Each technology is optimized for different scenarios. Containers excel at lifting and shifting existing, complex applications that depend on a full POSIX-compliant environment, such as databases or legacy monolithic services. WebAssembly shines in the world of greenfield, cloud-native development, offering a lighter, faster, and more secure foundation for building the next generation of microservices and serverless functions.\n\n### New Foundations for Platform Engineering: The Cloud and the Edge\n\nFor WebAssembly to fulfill its potential as a server-side technology, it must integrate seamlessly into the dominant paradigm for cloud infrastructure management: Kubernetes. This integration is not just possible; it is already well underway, enabled by the extensible architecture of the cloud-native ecosystem. At its core, Kubernetes orchestrates workloads by communicating with a high-level container runtime, such as containerd, on each of its worker nodes. This high-level runtime is responsible for managing images and container lifecycles, but it delegates the actual task of running a process to a low-level runtime. For traditional Linux containers, this runtime is typically *runc*.\n\nThe key to running Wasm on Kubernetes lies in replacing this final link in the chain. Projects like [runwasi](https://github.com/containerd/runwasi) provide a \"shim\", a small piece of software that acts as a bridge, allowing containerd to communicate with a WebAssembly runtime (like Wasmtime or WasmEdge) just as it would with *runc*. This makes the Wasm runtime appear to Kubernetes as just another way to run workloads. The final piece of the integration is a Kubernetes object called a *RuntimeClass*, which acts as a label. By applying this label to a workload definition, developers can instruct the Kubernetes scheduler to deploy that specific workload to nodes configured with the Wasm shim, enabling Wasm modules and traditional containers to run side-by-side within the same cluster. Projects like [SpinKube](https://www.spinkube.dev/) are emerging to automate this entire setup process, making it easier for organizations to adopt Wasm without rebuilding their infrastructure from scratch.\n\nThis deep integration enables new and more efficient approaches to platform engineering: the discipline of building and managing the internal platforms that development teams use to ship software. In this pattern, the platform team provides standardized components that encapsulate common, cross-cutting concerns like logging, metrics, network access, and security policies. Application developers, in turn, focus solely on writing a \"user\" component that contains pure business logic. At deployment time, these two pieces are composed into a single, tiny, and secure Wasm binary. This creates a powerful separation of concerns. Developers are freed from boilerplate code and infrastructure details, while the platform team can enforce standards, patch vulnerabilities, and evolve the platform's capabilities centrally and transparently, without requiring application teams to rebuild or redeploy their code.\n\nWhile these patterns are transforming the cloud, it is at the network's edge where WebAssembly's advantages become not just beneficial, but essential. Edge computing involves moving computation away from centralized data centers and closer to where data is generated and consumed: on IoT devices, in factory machinery, at retail locations, or within telecommunication networks. These environments are often severely resource-constrained, with limited CPU, memory, and power, making heavyweight containers impractical or impossible to run.\n\nWebAssembly is a near-perfect fit for this world. Its incredibly small binary size and minimal resource footprint allow it to run on devices where containers cannot. Its near-instantaneous startup times are critical for the event-driven, real-time processing required in many edge scenarios. And its true platform independence, the ability for a single compiled binary to run on any CPU architecture, be it x86, ARM, or RISC-V, is a necessity in the heterogeneous hardware landscape of the edge. This has unlocked a new wave of applications, from running machine learning inference models to executing dynamic logic within Content Delivery Networks (CDNs) with ultra-low latency.\n\nThe ability of WebAssembly to operate seamlessly across these diverse environments reveals its most profound impact. Historically, software development has been siloed; building for the browser, the cloud, and embedded devices required different tools, different languages, and different deployment models. Containers helped unify deployment in the cloud, but they are foreign to the browser and too cumbersome for much of the edge. WebAssembly is the first technology to provide a single, consistent application runtime that spans this entire compute continuum. The true strength of WebAssembly lies in how its ecosystem bridges the historically separate worlds of the browser, cloud, and edge. While the final.wasm module is often tailored for its specific environment, Wasm as a standard provides a common compilation target. This allows developers to deploy applications across a vast spectrum: from a rich user interface in a web browser, to large-scale processing orchestrated by Kubernetes, and even to tiny, resource-constrained IoT devices. This reality enables a future where developers write their core business logic once and can deploy it to the most appropriate location: close to the user for low latency, in the cloud for heavy computation, or in the browser for interactivity without needing to rewrite or repackage it. This capability breaks down the architectural barriers that have long defined distributed systems, paving the way for a truly fluid and unified model of computation.\n\n### The Future is Composable: The WebAssembly Component Model\n\nDespite its portability and security, a final, fundamental challenge has historically limited WebAssembly's potential: true interoperability. While a single Wasm module is a self-contained unit, getting multiple modules to communicate with each other effectively has been remarkably difficult. The core Wasm specification only allows for the passing of simple numeric types, integers and floats, between modules. Exchanging more complex data structures like strings, lists, or objects requires developers to manually manage pointers and memory layouts, a process that is deeply tied to the conventions of the source language and compiler. This \"impedance mismatch\" means that a Wasm module compiled from Rust cannot easily call a function in a module compiled from Go, as they represent data in fundamentally incompatible ways. This has been the primary barrier to creating a vibrant, language-agnostic ecosystem of reusable Wasm libraries, forcing developers into fragile, language-specific linking models where modules must share a single linear memory space.\n\nThe [WebAssembly Component Model](https://component-model.bytecodealliance.org/) is the ambitious proposal designed to solve this final challenge. **It is critical, however, to understand its current status: the Component Model is an active proposal under development, not a finalized W3C standard**. While tooling and runtimes are rapidly implementing it, the specification is still subject to change. It is an evolution of the core standard that elevates Wasm from a format for individual, isolated modules into a system for building complex applications from smaller, interoperable, and language-agnostic parts. The most effective analogy for the Component Model is that it turns Wasm modules into standardized \"LEGO bricks\". Each component is a self-contained, reusable piece of software with well-defined connection points, allowing them to be snapped together to build something larger.\n\nTwo key concepts make this possible: **WIT** and ‚Äú **worlds** ‚Äù. The WebAssembly Interface Type (WIT) is an Interface Definition Language (IDL) used to describe the \"shape\" of the connectors on these metaphorical LEGO bricks. A WIT file defines the high-level functions and rich data types such as strings, lists, variants, and records that a component either **exports** (provides to others) or **imports** (requires from its environment).\n\nCrucially, the standard **WASI interfaces** themselves (e.g. for filesystems or sockets) are also defined using WIT. This means developers can use the exact same language to extend the default system capabilities with their own **domain-specific interfaces**, creating a unified and powerful way to describe any interaction.\n\nA \"world\" is a WIT definition that describes the complete set of interfaces a component interacts with, effectively declaring all of its capabilities and dependencies. Tooling built around the Component Model, such as [wit-bindgen](https://github.com/bytecodealliance/wit-bindgen), then automatically generates the necessary \"binding code\" for each language. This code handles the complex task of translating data between a language's native representation (e.g., a Rust String or a Python list) and a standardized, language-agnostic memory layout known as the [Canonical ABI](https://component-model.bytecodealliance.org/advanced/canonical-abi.html). The result is seamless interoperability: a component written in C++ can call a function exported by a component written in TinyGo, passing complex data back and forth as if they were native libraries in the same language, without either needing any knowledge of the other's internal implementation.\n\nThis enables a fundamentally different approach to software composition compared to the container world. Container-based architectures are typically composed at design time. Developers build discrete services, package them into containers, and then define how they interact, usually over a network via APIs, using orchestration configurations like Kubernetes manifests or Docker Compose files. This is a model for composing distributed systems. The WebAssembly Component Model enables granular composition at runtime. Components communicate through fast, standardized in-memory interfaces rather than network protocols, allowing them to be linked together within the same process. This creates a model for building applications from secure, sandboxed, and interchangeable parts.\n\nA prime example is [wasmCloud](https://wasmcloud.com/docs/concepts/linking-components/linking-at-runtime/). In this platform, components (called actors) declare dependencies on abstract interfaces, like a key-value store. At runtime, they are dynamically linked to providers that offer concrete implementations (e.g. a Redis provider).\n\nThe key advantage is that these links can be changed on the fly. You can swap the Redis provider for a different one without restarting or recompiling the application, perfectly realizing the goal of building flexible systems from truly interchangeable parts.\n\nThis shift from source-level libraries to compiled, sandboxed components as the fundamental unit of software reuse represents a paradigm shift. It is the technical realization of architectural concepts like Packaged Business Capabilities (PBCs), where distinct business functions are encapsulated as autonomous, deployable software components. A Wasm component provides a near-perfect implementation of a PBC: it is a compiled, portable, and secure artifact that encapsulates specific logic. The Component Model, therefore, is not just a technical upgrade for linking code. It is the foundation for a future where software is no longer just written, but composed. Developers will be able to assemble applications from a universal ecosystem of secure, pre-built components that provide best-of-breed solutions for specific tasks, fundamentally altering the nature of the software supply chain and accelerating innovation across all languages and platforms.\n\n### Conclusion: From a Faster Web to a Universal Runtime\n\nWebAssembly's journey has been one of remarkable and accelerating evolution. Born from the practical need to overcome performance bottlenecks in the web browser, its core principles of speed, portability, and security proved to be far more powerful than its creators may have initially envisioned. What began as a way to run C++ code alongside JavaScript has grown into a technology that is fundamentally reshaping our conception of software.\n\nThe introduction of the WebAssembly System Interface (WASI) was the pivotal moment, transforming Wasm from a browser-centric tool into a viable, universal runtime for server-side computing. Its capability-based security model offered a fresh, \"secure-by-default\" alternative to traditional application architectures. This new foundation allowed Wasm to emerge as a compelling counterpart to containers, offering an unparalleled combination of lightweight footprint, near-instantaneous startup, and a hardened security sandbox that is ideally suited for the demands of serverless functions and the resource-constrained world of edge computing. Today, Wasm is not just a technology for the browser, the cloud, or the edge; it is the first to provide a single, consistent runtime that spans this entire continuum, breaking down long-standing silos in software development.\n\nNow, with the advent of the Component Model, WebAssembly is poised for its next great leap. By solving the final, critical challenge of language-agnostic interoperability, it lays the groundwork for a future where applications are not monoliths to be built, but solutions to be composed from a global ecosystem of secure, reusable, and portable software components. WebAssembly is more than just a faster way to run code; it is a foundational shift toward a more modular, more secure, and truly universal paradigm for the next era of computing.","metadata":{"title":"WebAssembly: From Browser Plugin to the Next Universal Runtime","excerpt":"Explore WebAssembly's evolution from a browser performance booster to a universal runtime reshaping cloud, edge, and distributed computing with near-native performance across platforms.","date":"2025-08-04","author":"Graziano Casto"}}]},"schema":{"@context":"https://schema.org","@type":"WebSite","name":"Graziano Casto WebSite","alternateName":"Graziano's WebSite","url":"https://castograziano.com"}},"__N_SSG":true},"page":"/","query":{},"buildId":"cX5uW1vCazRxt3VxGRD10","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>